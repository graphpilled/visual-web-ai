<!DOCTYPE html>
<html>
<head>
  <title>INT4 - The Final 5.4%</title>
  <style>
    body { font-family: monospace; padding: 20px; background: #1a1a2e; color: #eee; }
    pre { background: #16213e; padding: 15px; border-radius: 8px; }
    .pass { color: #4ade80; }
    .fail { color: #f87171; }
    .warn { color: #fbbf24; }
    .header { color: #c084fc; font-weight: bold; }
  </style>
</head>
<body>
  <h1>INT4 - Hunting the Final 5.4%</h1>
  <pre id="output"></pre>
  <script type="module">
    const log = (msg, cls = '') => {
      const span = cls ? `<span class="${cls}">${msg}</span>` : msg;
      document.getElementById('output').innerHTML += span + '\n';
    };

    function quantizeTransposed(K, N, groupSize) {
      const numGroups = Math.ceil(K / groupSize);
      const packedK = Math.ceil(K / 8);
      const packed = new Uint32Array(packedK * N);
      const scales = new Float32Array(numGroups * N);
      for (let i = 0; i < packed.length; i++) packed[i] = Math.random() * 0xFFFFFFFF >>> 0;
      for (let i = 0; i < scales.length; i++) scales[i] = Math.random() * 0.1;
      return { packed, scales, packedK, numGroups };
    }

    // V23 baseline (our current best)
    function createV23(K, N, groupSize) {
      const packedK = Math.ceil(K / 8);
      const numGroups = Math.ceil(K / groupSize);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;
const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = 16u;
@compute @workgroup_size(64)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  var sum = 0.0;
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let s = scales[g * N + col];
    let base = g * PACKED_PER_GROUP;
    var acc = 0.0;
    let p0 = b_packed[base * N + col];
    let p1 = b_packed[(base + 1u) * N + col];
    let p2 = b_packed[(base + 2u) * N + col];
    let p3 = b_packed[(base + 3u) * N + col];
    let p4 = b_packed[(base + 4u) * N + col];
    let p5 = b_packed[(base + 5u) * N + col];
    let p6 = b_packed[(base + 6u) * N + col];
    let p7 = b_packed[(base + 7u) * N + col];
    let k0 = base * 8u;
    let a0 = a[k0/4u]; let a1 = a[k0/4u+1u]; let a2 = a[k0/4u+2u]; let a3 = a[k0/4u+3u];
    let a4 = a[k0/4u+4u]; let a5 = a[k0/4u+5u]; let a6 = a[k0/4u+6u]; let a7 = a[k0/4u+7u];
    let a8 = a[k0/4u+8u]; let a9 = a[k0/4u+9u]; let a10 = a[k0/4u+10u]; let a11 = a[k0/4u+11u];
    let a12 = a[k0/4u+12u]; let a13 = a[k0/4u+13u]; let a14 = a[k0/4u+14u]; let a15 = a[k0/4u+15u];
    acc += dot(a0, vec4<f32>(f32((p0>>0u)&0xFu)-8.0, f32((p0>>4u)&0xFu)-8.0, f32((p0>>8u)&0xFu)-8.0, f32((p0>>12u)&0xFu)-8.0));
    acc += dot(a1, vec4<f32>(f32((p0>>16u)&0xFu)-8.0, f32((p0>>20u)&0xFu)-8.0, f32((p0>>24u)&0xFu)-8.0, f32((p0>>28u)&0xFu)-8.0));
    acc += dot(a2, vec4<f32>(f32((p1>>0u)&0xFu)-8.0, f32((p1>>4u)&0xFu)-8.0, f32((p1>>8u)&0xFu)-8.0, f32((p1>>12u)&0xFu)-8.0));
    acc += dot(a3, vec4<f32>(f32((p1>>16u)&0xFu)-8.0, f32((p1>>20u)&0xFu)-8.0, f32((p1>>24u)&0xFu)-8.0, f32((p1>>28u)&0xFu)-8.0));
    acc += dot(a4, vec4<f32>(f32((p2>>0u)&0xFu)-8.0, f32((p2>>4u)&0xFu)-8.0, f32((p2>>8u)&0xFu)-8.0, f32((p2>>12u)&0xFu)-8.0));
    acc += dot(a5, vec4<f32>(f32((p2>>16u)&0xFu)-8.0, f32((p2>>20u)&0xFu)-8.0, f32((p2>>24u)&0xFu)-8.0, f32((p2>>28u)&0xFu)-8.0));
    acc += dot(a6, vec4<f32>(f32((p3>>0u)&0xFu)-8.0, f32((p3>>4u)&0xFu)-8.0, f32((p3>>8u)&0xFu)-8.0, f32((p3>>12u)&0xFu)-8.0));
    acc += dot(a7, vec4<f32>(f32((p3>>16u)&0xFu)-8.0, f32((p3>>20u)&0xFu)-8.0, f32((p3>>24u)&0xFu)-8.0, f32((p3>>28u)&0xFu)-8.0));
    acc += dot(a8, vec4<f32>(f32((p4>>0u)&0xFu)-8.0, f32((p4>>4u)&0xFu)-8.0, f32((p4>>8u)&0xFu)-8.0, f32((p4>>12u)&0xFu)-8.0));
    acc += dot(a9, vec4<f32>(f32((p4>>16u)&0xFu)-8.0, f32((p4>>20u)&0xFu)-8.0, f32((p4>>24u)&0xFu)-8.0, f32((p4>>28u)&0xFu)-8.0));
    acc += dot(a10, vec4<f32>(f32((p5>>0u)&0xFu)-8.0, f32((p5>>4u)&0xFu)-8.0, f32((p5>>8u)&0xFu)-8.0, f32((p5>>12u)&0xFu)-8.0));
    acc += dot(a11, vec4<f32>(f32((p5>>16u)&0xFu)-8.0, f32((p5>>20u)&0xFu)-8.0, f32((p5>>24u)&0xFu)-8.0, f32((p5>>28u)&0xFu)-8.0));
    acc += dot(a12, vec4<f32>(f32((p6>>0u)&0xFu)-8.0, f32((p6>>4u)&0xFu)-8.0, f32((p6>>8u)&0xFu)-8.0, f32((p6>>12u)&0xFu)-8.0));
    acc += dot(a13, vec4<f32>(f32((p6>>16u)&0xFu)-8.0, f32((p6>>20u)&0xFu)-8.0, f32((p6>>24u)&0xFu)-8.0, f32((p6>>28u)&0xFu)-8.0));
    acc += dot(a14, vec4<f32>(f32((p7>>0u)&0xFu)-8.0, f32((p7>>4u)&0xFu)-8.0, f32((p7>>8u)&0xFu)-8.0, f32((p7>>12u)&0xFu)-8.0));
    acc += dot(a15, vec4<f32>(f32((p7>>16u)&0xFu)-8.0, f32((p7>>20u)&0xFu)-8.0, f32((p7>>24u)&0xFu)-8.0, f32((p7>>28u)&0xFu)-8.0));
    let q0 = b_packed[(base + 8u) * N + col];
    let q1 = b_packed[(base + 9u) * N + col];
    let q2 = b_packed[(base + 10u) * N + col];
    let q3 = b_packed[(base + 11u) * N + col];
    let q4 = b_packed[(base + 12u) * N + col];
    let q5 = b_packed[(base + 13u) * N + col];
    let q6 = b_packed[(base + 14u) * N + col];
    let q7 = b_packed[(base + 15u) * N + col];
    let k1 = (base + 8u) * 8u;
    let b0 = a[k1/4u]; let b1 = a[k1/4u+1u]; let b2 = a[k1/4u+2u]; let b3 = a[k1/4u+3u];
    let b4 = a[k1/4u+4u]; let b5 = a[k1/4u+5u]; let b6 = a[k1/4u+6u]; let b7 = a[k1/4u+7u];
    let b8 = a[k1/4u+8u]; let b9 = a[k1/4u+9u]; let b10 = a[k1/4u+10u]; let b11 = a[k1/4u+11u];
    let b12 = a[k1/4u+12u]; let b13 = a[k1/4u+13u]; let b14 = a[k1/4u+14u]; let b15 = a[k1/4u+15u];
    acc += dot(b0, vec4<f32>(f32((q0>>0u)&0xFu)-8.0, f32((q0>>4u)&0xFu)-8.0, f32((q0>>8u)&0xFu)-8.0, f32((q0>>12u)&0xFu)-8.0));
    acc += dot(b1, vec4<f32>(f32((q0>>16u)&0xFu)-8.0, f32((q0>>20u)&0xFu)-8.0, f32((q0>>24u)&0xFu)-8.0, f32((q0>>28u)&0xFu)-8.0));
    acc += dot(b2, vec4<f32>(f32((q1>>0u)&0xFu)-8.0, f32((q1>>4u)&0xFu)-8.0, f32((q1>>8u)&0xFu)-8.0, f32((q1>>12u)&0xFu)-8.0));
    acc += dot(b3, vec4<f32>(f32((q1>>16u)&0xFu)-8.0, f32((q1>>20u)&0xFu)-8.0, f32((q1>>24u)&0xFu)-8.0, f32((q1>>28u)&0xFu)-8.0));
    acc += dot(b4, vec4<f32>(f32((q2>>0u)&0xFu)-8.0, f32((q2>>4u)&0xFu)-8.0, f32((q2>>8u)&0xFu)-8.0, f32((q2>>12u)&0xFu)-8.0));
    acc += dot(b5, vec4<f32>(f32((q2>>16u)&0xFu)-8.0, f32((q2>>20u)&0xFu)-8.0, f32((q2>>24u)&0xFu)-8.0, f32((q2>>28u)&0xFu)-8.0));
    acc += dot(b6, vec4<f32>(f32((q3>>0u)&0xFu)-8.0, f32((q3>>4u)&0xFu)-8.0, f32((q3>>8u)&0xFu)-8.0, f32((q3>>12u)&0xFu)-8.0));
    acc += dot(b7, vec4<f32>(f32((q3>>16u)&0xFu)-8.0, f32((q3>>20u)&0xFu)-8.0, f32((q3>>24u)&0xFu)-8.0, f32((q3>>28u)&0xFu)-8.0));
    acc += dot(b8, vec4<f32>(f32((q4>>0u)&0xFu)-8.0, f32((q4>>4u)&0xFu)-8.0, f32((q4>>8u)&0xFu)-8.0, f32((q4>>12u)&0xFu)-8.0));
    acc += dot(b9, vec4<f32>(f32((q4>>16u)&0xFu)-8.0, f32((q4>>20u)&0xFu)-8.0, f32((q4>>24u)&0xFu)-8.0, f32((q4>>28u)&0xFu)-8.0));
    acc += dot(b10, vec4<f32>(f32((q5>>0u)&0xFu)-8.0, f32((q5>>4u)&0xFu)-8.0, f32((q5>>8u)&0xFu)-8.0, f32((q5>>12u)&0xFu)-8.0));
    acc += dot(b11, vec4<f32>(f32((q5>>16u)&0xFu)-8.0, f32((q5>>20u)&0xFu)-8.0, f32((q5>>24u)&0xFu)-8.0, f32((q5>>28u)&0xFu)-8.0));
    acc += dot(b12, vec4<f32>(f32((q6>>0u)&0xFu)-8.0, f32((q6>>4u)&0xFu)-8.0, f32((q6>>8u)&0xFu)-8.0, f32((q6>>12u)&0xFu)-8.0));
    acc += dot(b13, vec4<f32>(f32((q6>>16u)&0xFu)-8.0, f32((q6>>20u)&0xFu)-8.0, f32((q6>>24u)&0xFu)-8.0, f32((q6>>28u)&0xFu)-8.0));
    acc += dot(b14, vec4<f32>(f32((q7>>0u)&0xFu)-8.0, f32((q7>>4u)&0xFu)-8.0, f32((q7>>8u)&0xFu)-8.0, f32((q7>>12u)&0xFu)-8.0));
    acc += dot(b15, vec4<f32>(f32((q7>>16u)&0xFu)-8.0, f32((q7>>20u)&0xFu)-8.0, f32((q7>>24u)&0xFu)-8.0, f32((q7>>28u)&0xFu)-8.0));
    sum += acc * s;
  }
  output[col] = sum;
}`;
    }

    // V24: Use vec4<u32> extractBits - might be faster
    function createV24(K, N, groupSize) {
      const packedK = Math.ceil(K / 8);
      const numGroups = Math.ceil(K / groupSize);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;
const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = 16u;

fn dequant_lo(p: u32) -> vec4<f32> {
  return vec4<f32>(
    f32(extractBits(p, 0u, 4u)) - 8.0,
    f32(extractBits(p, 4u, 4u)) - 8.0,
    f32(extractBits(p, 8u, 4u)) - 8.0,
    f32(extractBits(p, 12u, 4u)) - 8.0
  );
}

fn dequant_hi(p: u32) -> vec4<f32> {
  return vec4<f32>(
    f32(extractBits(p, 16u, 4u)) - 8.0,
    f32(extractBits(p, 20u, 4u)) - 8.0,
    f32(extractBits(p, 24u, 4u)) - 8.0,
    f32(extractBits(p, 28u, 4u)) - 8.0
  );
}

@compute @workgroup_size(64)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  var sum = 0.0;
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let s = scales[g * N + col];
    let base = g * PACKED_PER_GROUP;
    var acc = 0.0;
    
    for (var i = 0u; i < 16u; i++) {
      let p = b_packed[(base + i) * N + col];
      let k = (base + i) * 8u;
      let a_lo = a[k/4u];
      let a_hi = a[k/4u + 1u];
      acc += dot(a_lo, dequant_lo(p)) + dot(a_hi, dequant_hi(p));
    }
    sum += acc * s;
  }
  output[col] = sum;
}`;
    }

    // V25: Use integer arithmetic - compute dot in int, convert once
    function createV25(K, N, groupSize) {
      const packedK = Math.ceil(K / 8);
      const numGroups = Math.ceil(K / groupSize);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;
const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = 16u;

@compute @workgroup_size(64)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  var sum = 0.0;
  
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let s = scales[g * N + col];
    let base = g * PACKED_PER_GROUP;
    var acc = 0.0;
    
    // Process 16 packed values for this group
    for (var i = 0u; i < 16u; i += 4u) {
      let p0 = b_packed[(base + i) * N + col];
      let p1 = b_packed[(base + i + 1u) * N + col];
      let p2 = b_packed[(base + i + 2u) * N + col];
      let p3 = b_packed[(base + i + 3u) * N + col];
      
      let k = (base + i) * 8u;
      
      // Load 8 activation vec4s
      let a0 = a[k/4u]; let a1 = a[k/4u+1u];
      let a2 = a[k/4u+2u]; let a3 = a[k/4u+3u];
      let a4 = a[k/4u+4u]; let a5 = a[k/4u+5u];
      let a6 = a[k/4u+6u]; let a7 = a[k/4u+7u];
      
      // Dequant and accumulate
      acc += dot(a0, vec4<f32>(f32((p0>>0u)&0xFu)-8.0, f32((p0>>4u)&0xFu)-8.0, f32((p0>>8u)&0xFu)-8.0, f32((p0>>12u)&0xFu)-8.0));
      acc += dot(a1, vec4<f32>(f32((p0>>16u)&0xFu)-8.0, f32((p0>>20u)&0xFu)-8.0, f32((p0>>24u)&0xFu)-8.0, f32((p0>>28u)&0xFu)-8.0));
      acc += dot(a2, vec4<f32>(f32((p1>>0u)&0xFu)-8.0, f32((p1>>4u)&0xFu)-8.0, f32((p1>>8u)&0xFu)-8.0, f32((p1>>12u)&0xFu)-8.0));
      acc += dot(a3, vec4<f32>(f32((p1>>16u)&0xFu)-8.0, f32((p1>>20u)&0xFu)-8.0, f32((p1>>24u)&0xFu)-8.0, f32((p1>>28u)&0xFu)-8.0));
      acc += dot(a4, vec4<f32>(f32((p2>>0u)&0xFu)-8.0, f32((p2>>4u)&0xFu)-8.0, f32((p2>>8u)&0xFu)-8.0, f32((p2>>12u)&0xFu)-8.0));
      acc += dot(a5, vec4<f32>(f32((p2>>16u)&0xFu)-8.0, f32((p2>>20u)&0xFu)-8.0, f32((p2>>24u)&0xFu)-8.0, f32((p2>>28u)&0xFu)-8.0));
      acc += dot(a6, vec4<f32>(f32((p3>>0u)&0xFu)-8.0, f32((p3>>4u)&0xFu)-8.0, f32((p3>>8u)&0xFu)-8.0, f32((p3>>12u)&0xFu)-8.0));
      acc += dot(a7, vec4<f32>(f32((p3>>16u)&0xFu)-8.0, f32((p3>>20u)&0xFu)-8.0, f32((p3>>24u)&0xFu)-8.0, f32((p3>>28u)&0xFu)-8.0));
    }
    sum += acc * s;
  }
  output[col] = sum;
}`;
    }

    // V26: Pre-subtract 8 from activation, don't subtract from weights
    // If we store weights as 0-15 (unsigned) and precompute a' = a * (-8), then:
    // sum(a * (w - 8)) = sum(a * w) + sum(a * -8) = sum(a * w) + sum(a') 
    // We can precompute sum(a') once per output!
    function createV26(K, N, groupSize) {
      const packedK = Math.ceil(K / 8);
      const numGroups = Math.ceil(K / groupSize);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;
const N = ${N}u;
const K4 = ${K/4}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = 16u;

@compute @workgroup_size(64)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  
  // Precompute sum of activations (for the -8 offset)
  var a_sum = 0.0;
  for (var i = 0u; i < K4; i++) {
    let v = a[i];
    a_sum += v.x + v.y + v.z + v.w;
  }
  
  var sum = 0.0;
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let s = scales[g * N + col];
    let base = g * PACKED_PER_GROUP;
    var acc = 0.0;
    
    for (var i = 0u; i < 16u; i++) {
      let p = b_packed[(base + i) * N + col];
      let k = (base + i) * 8u;
      let a_lo = a[k/4u];
      let a_hi = a[k/4u + 1u];
      
      // Unsigned dequant (0-15 range, no -8)
      let w_lo = vec4<f32>(f32((p>>0u)&0xFu), f32((p>>4u)&0xFu), f32((p>>8u)&0xFu), f32((p>>12u)&0xFu));
      let w_hi = vec4<f32>(f32((p>>16u)&0xFu), f32((p>>20u)&0xFu), f32((p>>24u)&0xFu), f32((p>>28u)&0xFu));
      
      acc += dot(a_lo, w_lo) + dot(a_hi, w_hi);
    }
    // Subtract the offset: acc contains sum(a * w_unsigned), need sum(a * (w - 8))
    // = sum(a * w) - 8 * sum(a_in_group)
    // But a_sum is for all K, we need per-group...
    // Actually this doesn't work cleanly with per-group scales. Let's try differently.
    sum += acc * s;
  }
  
  // Approximate offset correction (not mathematically correct with per-group scales)
  // This is experimental
  output[col] = sum - a_sum * 8.0 * scales[0];  // Wrong but let's see perf
}`;
    }

    // V27: Bit manipulation - use vec4<u32> and unpack
    function createV27(K, N, groupSize) {
      const packedK = Math.ceil(K / 8);
      const numGroups = Math.ceil(K / groupSize);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;
const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = 16u;

// Use vec4 operations for extraction
fn extract4(p: u32) -> vec4<f32> {
  let v = vec4<u32>(p, p >> 4u, p >> 8u, p >> 12u) & vec4<u32>(0xFu);
  return vec4<f32>(v) - vec4<f32>(8.0);
}

fn extract4_hi(p: u32) -> vec4<f32> {
  let v = vec4<u32>(p >> 16u, p >> 20u, p >> 24u, p >> 28u) & vec4<u32>(0xFu);
  return vec4<f32>(v) - vec4<f32>(8.0);
}

@compute @workgroup_size(64)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  var sum = 0.0;
  
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let s = scales[g * N + col];
    let base = g * PACKED_PER_GROUP;
    var acc = 0.0;
    
    for (var i = 0u; i < 16u; i++) {
      let p = b_packed[(base + i) * N + col];
      let k = (base + i) * 8u;
      acc += dot(a[k/4u], extract4(p)) + dot(a[k/4u + 1u], extract4_hi(p));
    }
    sum += acc * s;
  }
  output[col] = sum;
}`;
    }

    // V28: Fused multiply-add reordering
    function createV28(K, N, groupSize) {
      const packedK = Math.ceil(K / 8);
      const numGroups = Math.ceil(K / groupSize);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;
const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = 16u;

@compute @workgroup_size(64)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  var sum = 0.0;
  
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let s = scales[g * N + col];
    let base = g * PACKED_PER_GROUP;
    
    // Accumulate in groups of 4 to enable FMA
    var acc0 = 0.0; var acc1 = 0.0; var acc2 = 0.0; var acc3 = 0.0;
    
    for (var i = 0u; i < 16u; i += 4u) {
      let p0 = b_packed[(base + i) * N + col];
      let p1 = b_packed[(base + i + 1u) * N + col];
      let p2 = b_packed[(base + i + 2u) * N + col];
      let p3 = b_packed[(base + i + 3u) * N + col];
      
      let k = (base + i) * 8u;
      let a0 = a[k/4u]; let a1 = a[k/4u+1u]; let a2 = a[k/4u+2u]; let a3 = a[k/4u+3u];
      let a4 = a[k/4u+4u]; let a5 = a[k/4u+5u]; let a6 = a[k/4u+6u]; let a7 = a[k/4u+7u];
      
      acc0 = fma(a0.x, f32((p0>>0u)&0xFu)-8.0, acc0);
      acc0 = fma(a0.y, f32((p0>>4u)&0xFu)-8.0, acc0);
      acc0 = fma(a0.z, f32((p0>>8u)&0xFu)-8.0, acc0);
      acc0 = fma(a0.w, f32((p0>>12u)&0xFu)-8.0, acc0);
      acc1 = fma(a1.x, f32((p0>>16u)&0xFu)-8.0, acc1);
      acc1 = fma(a1.y, f32((p0>>20u)&0xFu)-8.0, acc1);
      acc1 = fma(a1.z, f32((p0>>24u)&0xFu)-8.0, acc1);
      acc1 = fma(a1.w, f32((p0>>28u)&0xFu)-8.0, acc1);
      
      acc2 = fma(a2.x, f32((p1>>0u)&0xFu)-8.0, acc2);
      acc2 = fma(a2.y, f32((p1>>4u)&0xFu)-8.0, acc2);
      acc2 = fma(a2.z, f32((p1>>8u)&0xFu)-8.0, acc2);
      acc2 = fma(a2.w, f32((p1>>12u)&0xFu)-8.0, acc2);
      acc3 = fma(a3.x, f32((p1>>16u)&0xFu)-8.0, acc3);
      acc3 = fma(a3.y, f32((p1>>20u)&0xFu)-8.0, acc3);
      acc3 = fma(a3.z, f32((p1>>24u)&0xFu)-8.0, acc3);
      acc3 = fma(a3.w, f32((p1>>28u)&0xFu)-8.0, acc3);
      
      acc0 = fma(a4.x, f32((p2>>0u)&0xFu)-8.0, acc0);
      acc0 = fma(a4.y, f32((p2>>4u)&0xFu)-8.0, acc0);
      acc0 = fma(a4.z, f32((p2>>8u)&0xFu)-8.0, acc0);
      acc0 = fma(a4.w, f32((p2>>12u)&0xFu)-8.0, acc0);
      acc1 = fma(a5.x, f32((p2>>16u)&0xFu)-8.0, acc1);
      acc1 = fma(a5.y, f32((p2>>20u)&0xFu)-8.0, acc1);
      acc1 = fma(a5.z, f32((p2>>24u)&0xFu)-8.0, acc1);
      acc1 = fma(a5.w, f32((p2>>28u)&0xFu)-8.0, acc1);
      
      acc2 = fma(a6.x, f32((p3>>0u)&0xFu)-8.0, acc2);
      acc2 = fma(a6.y, f32((p3>>4u)&0xFu)-8.0, acc2);
      acc2 = fma(a6.z, f32((p3>>8u)&0xFu)-8.0, acc2);
      acc2 = fma(a6.w, f32((p3>>12u)&0xFu)-8.0, acc2);
      acc3 = fma(a7.x, f32((p3>>16u)&0xFu)-8.0, acc3);
      acc3 = fma(a7.y, f32((p3>>20u)&0xFu)-8.0, acc3);
      acc3 = fma(a7.z, f32((p3>>24u)&0xFu)-8.0, acc3);
      acc3 = fma(a7.w, f32((p3>>28u)&0xFu)-8.0, acc3);
    }
    sum += (acc0 + acc1 + acc2 + acc3) * s;
  }
  output[col] = sum;
}`;
    }

    // V29: Try wg=48 (might fit better on some GPUs)
    function createV29(K, N, groupSize) {
      const packedK = Math.ceil(K / 8);
      const numGroups = Math.ceil(K / groupSize);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;
const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = 16u;
@compute @workgroup_size(48)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  var sum = 0.0;
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let s = scales[g * N + col];
    let base = g * PACKED_PER_GROUP;
    var acc = 0.0;
    let p0 = b_packed[base * N + col];
    let p1 = b_packed[(base + 1u) * N + col];
    let p2 = b_packed[(base + 2u) * N + col];
    let p3 = b_packed[(base + 3u) * N + col];
    let p4 = b_packed[(base + 4u) * N + col];
    let p5 = b_packed[(base + 5u) * N + col];
    let p6 = b_packed[(base + 6u) * N + col];
    let p7 = b_packed[(base + 7u) * N + col];
    let k0 = base * 8u;
    let a0 = a[k0/4u]; let a1 = a[k0/4u+1u]; let a2 = a[k0/4u+2u]; let a3 = a[k0/4u+3u];
    let a4 = a[k0/4u+4u]; let a5 = a[k0/4u+5u]; let a6 = a[k0/4u+6u]; let a7 = a[k0/4u+7u];
    let a8 = a[k0/4u+8u]; let a9 = a[k0/4u+9u]; let a10 = a[k0/4u+10u]; let a11 = a[k0/4u+11u];
    let a12 = a[k0/4u+12u]; let a13 = a[k0/4u+13u]; let a14 = a[k0/4u+14u]; let a15 = a[k0/4u+15u];
    acc += dot(a0, vec4<f32>(f32((p0>>0u)&0xFu)-8.0, f32((p0>>4u)&0xFu)-8.0, f32((p0>>8u)&0xFu)-8.0, f32((p0>>12u)&0xFu)-8.0));
    acc += dot(a1, vec4<f32>(f32((p0>>16u)&0xFu)-8.0, f32((p0>>20u)&0xFu)-8.0, f32((p0>>24u)&0xFu)-8.0, f32((p0>>28u)&0xFu)-8.0));
    acc += dot(a2, vec4<f32>(f32((p1>>0u)&0xFu)-8.0, f32((p1>>4u)&0xFu)-8.0, f32((p1>>8u)&0xFu)-8.0, f32((p1>>12u)&0xFu)-8.0));
    acc += dot(a3, vec4<f32>(f32((p1>>16u)&0xFu)-8.0, f32((p1>>20u)&0xFu)-8.0, f32((p1>>24u)&0xFu)-8.0, f32((p1>>28u)&0xFu)-8.0));
    acc += dot(a4, vec4<f32>(f32((p2>>0u)&0xFu)-8.0, f32((p2>>4u)&0xFu)-8.0, f32((p2>>8u)&0xFu)-8.0, f32((p2>>12u)&0xFu)-8.0));
    acc += dot(a5, vec4<f32>(f32((p2>>16u)&0xFu)-8.0, f32((p2>>20u)&0xFu)-8.0, f32((p2>>24u)&0xFu)-8.0, f32((p2>>28u)&0xFu)-8.0));
    acc += dot(a6, vec4<f32>(f32((p3>>0u)&0xFu)-8.0, f32((p3>>4u)&0xFu)-8.0, f32((p3>>8u)&0xFu)-8.0, f32((p3>>12u)&0xFu)-8.0));
    acc += dot(a7, vec4<f32>(f32((p3>>16u)&0xFu)-8.0, f32((p3>>20u)&0xFu)-8.0, f32((p3>>24u)&0xFu)-8.0, f32((p3>>28u)&0xFu)-8.0));
    acc += dot(a8, vec4<f32>(f32((p4>>0u)&0xFu)-8.0, f32((p4>>4u)&0xFu)-8.0, f32((p4>>8u)&0xFu)-8.0, f32((p4>>12u)&0xFu)-8.0));
    acc += dot(a9, vec4<f32>(f32((p4>>16u)&0xFu)-8.0, f32((p4>>20u)&0xFu)-8.0, f32((p4>>24u)&0xFu)-8.0, f32((p4>>28u)&0xFu)-8.0));
    acc += dot(a10, vec4<f32>(f32((p5>>0u)&0xFu)-8.0, f32((p5>>4u)&0xFu)-8.0, f32((p5>>8u)&0xFu)-8.0, f32((p5>>12u)&0xFu)-8.0));
    acc += dot(a11, vec4<f32>(f32((p5>>16u)&0xFu)-8.0, f32((p5>>20u)&0xFu)-8.0, f32((p5>>24u)&0xFu)-8.0, f32((p5>>28u)&0xFu)-8.0));
    acc += dot(a12, vec4<f32>(f32((p6>>0u)&0xFu)-8.0, f32((p6>>4u)&0xFu)-8.0, f32((p6>>8u)&0xFu)-8.0, f32((p6>>12u)&0xFu)-8.0));
    acc += dot(a13, vec4<f32>(f32((p6>>16u)&0xFu)-8.0, f32((p6>>20u)&0xFu)-8.0, f32((p6>>24u)&0xFu)-8.0, f32((p6>>28u)&0xFu)-8.0));
    acc += dot(a14, vec4<f32>(f32((p7>>0u)&0xFu)-8.0, f32((p7>>4u)&0xFu)-8.0, f32((p7>>8u)&0xFu)-8.0, f32((p7>>12u)&0xFu)-8.0));
    acc += dot(a15, vec4<f32>(f32((p7>>16u)&0xFu)-8.0, f32((p7>>20u)&0xFu)-8.0, f32((p7>>24u)&0xFu)-8.0, f32((p7>>28u)&0xFu)-8.0));
    let q0 = b_packed[(base + 8u) * N + col];
    let q1 = b_packed[(base + 9u) * N + col];
    let q2 = b_packed[(base + 10u) * N + col];
    let q3 = b_packed[(base + 11u) * N + col];
    let q4 = b_packed[(base + 12u) * N + col];
    let q5 = b_packed[(base + 13u) * N + col];
    let q6 = b_packed[(base + 14u) * N + col];
    let q7 = b_packed[(base + 15u) * N + col];
    let k1 = (base + 8u) * 8u;
    let b0 = a[k1/4u]; let b1 = a[k1/4u+1u]; let b2 = a[k1/4u+2u]; let b3 = a[k1/4u+3u];
    let b4 = a[k1/4u+4u]; let b5 = a[k1/4u+5u]; let b6 = a[k1/4u+6u]; let b7 = a[k1/4u+7u];
    let b8 = a[k1/4u+8u]; let b9 = a[k1/4u+9u]; let b10 = a[k1/4u+10u]; let b11 = a[k1/4u+11u];
    let b12 = a[k1/4u+12u]; let b13 = a[k1/4u+13u]; let b14 = a[k1/4u+14u]; let b15 = a[k1/4u+15u];
    acc += dot(b0, vec4<f32>(f32((q0>>0u)&0xFu)-8.0, f32((q0>>4u)&0xFu)-8.0, f32((q0>>8u)&0xFu)-8.0, f32((q0>>12u)&0xFu)-8.0));
    acc += dot(b1, vec4<f32>(f32((q0>>16u)&0xFu)-8.0, f32((q0>>20u)&0xFu)-8.0, f32((q0>>24u)&0xFu)-8.0, f32((q0>>28u)&0xFu)-8.0));
    acc += dot(b2, vec4<f32>(f32((q1>>0u)&0xFu)-8.0, f32((q1>>4u)&0xFu)-8.0, f32((q1>>8u)&0xFu)-8.0, f32((q1>>12u)&0xFu)-8.0));
    acc += dot(b3, vec4<f32>(f32((q1>>16u)&0xFu)-8.0, f32((q1>>20u)&0xFu)-8.0, f32((q1>>24u)&0xFu)-8.0, f32((q1>>28u)&0xFu)-8.0));
    acc += dot(b4, vec4<f32>(f32((q2>>0u)&0xFu)-8.0, f32((q2>>4u)&0xFu)-8.0, f32((q2>>8u)&0xFu)-8.0, f32((q2>>12u)&0xFu)-8.0));
    acc += dot(b5, vec4<f32>(f32((q2>>16u)&0xFu)-8.0, f32((q2>>20u)&0xFu)-8.0, f32((q2>>24u)&0xFu)-8.0, f32((q2>>28u)&0xFu)-8.0));
    acc += dot(b6, vec4<f32>(f32((q3>>0u)&0xFu)-8.0, f32((q3>>4u)&0xFu)-8.0, f32((q3>>8u)&0xFu)-8.0, f32((q3>>12u)&0xFu)-8.0));
    acc += dot(b7, vec4<f32>(f32((q3>>16u)&0xFu)-8.0, f32((q3>>20u)&0xFu)-8.0, f32((q3>>24u)&0xFu)-8.0, f32((q3>>28u)&0xFu)-8.0));
    acc += dot(b8, vec4<f32>(f32((q4>>0u)&0xFu)-8.0, f32((q4>>4u)&0xFu)-8.0, f32((q4>>8u)&0xFu)-8.0, f32((q4>>12u)&0xFu)-8.0));
    acc += dot(b9, vec4<f32>(f32((q4>>16u)&0xFu)-8.0, f32((q4>>20u)&0xFu)-8.0, f32((q4>>24u)&0xFu)-8.0, f32((q4>>28u)&0xFu)-8.0));
    acc += dot(b10, vec4<f32>(f32((q5>>0u)&0xFu)-8.0, f32((q5>>4u)&0xFu)-8.0, f32((q5>>8u)&0xFu)-8.0, f32((q5>>12u)&0xFu)-8.0));
    acc += dot(b11, vec4<f32>(f32((q5>>16u)&0xFu)-8.0, f32((q5>>20u)&0xFu)-8.0, f32((q5>>24u)&0xFu)-8.0, f32((q5>>28u)&0xFu)-8.0));
    acc += dot(b12, vec4<f32>(f32((q6>>0u)&0xFu)-8.0, f32((q6>>4u)&0xFu)-8.0, f32((q6>>8u)&0xFu)-8.0, f32((q6>>12u)&0xFu)-8.0));
    acc += dot(b13, vec4<f32>(f32((q6>>16u)&0xFu)-8.0, f32((q6>>20u)&0xFu)-8.0, f32((q6>>24u)&0xFu)-8.0, f32((q6>>28u)&0xFu)-8.0));
    acc += dot(b14, vec4<f32>(f32((q7>>0u)&0xFu)-8.0, f32((q7>>4u)&0xFu)-8.0, f32((q7>>8u)&0xFu)-8.0, f32((q7>>12u)&0xFu)-8.0));
    acc += dot(b15, vec4<f32>(f32((q7>>16u)&0xFu)-8.0, f32((q7>>20u)&0xFu)-8.0, f32((q7>>24u)&0xFu)-8.0, f32((q7>>28u)&0xFu)-8.0));
    sum += acc * s;
  }
  output[col] = sum;
}`;
    }

    async function benchmark() {
      log('=== INT4 - Hunting the Final 5.4% ===\n', 'header');
      
      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice({
        requiredLimits: {
          maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,
          maxBufferSize: adapter.limits.maxBufferSize
        }
      });
      
      const K = 4096, N = 11008, GROUP_SIZE = 128;
      const q = quantizeTransposed(K, N, GROUP_SIZE);
      const aData = new Float32Array(K).fill(0.1);
      
      log(`Matrix: [1, ${K}] x [${K}, ${N}]`);
      log(`Ceiling: ~1.80ms (~12.5 GB/s)\n`);
      
      async function bench(name, shaderFn, wgSize) {
        const buffers = {
          a: device.createBuffer({ size: K * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
          packed: device.createBuffer({ size: q.packed.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
          scales: device.createBuffer({ size: q.scales.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
          output: device.createBuffer({ size: N * 4, usage: GPUBufferUsage.STORAGE })
        };
        
        device.queue.writeBuffer(buffers.a, 0, aData);
        device.queue.writeBuffer(buffers.packed, 0, q.packed);
        device.queue.writeBuffer(buffers.scales, 0, q.scales);
        
        const module = device.createShaderModule({ code: shaderFn(K, N, GROUP_SIZE) });
        const pipeline = device.createComputePipeline({
          layout: 'auto',
          compute: { module, entryPoint: 'main' }
        });
        
        const bindGroup = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [
            { binding: 0, resource: { buffer: buffers.a } },
            { binding: 1, resource: { buffer: buffers.packed } },
            { binding: 2, resource: { buffer: buffers.scales } },
            { binding: 3, resource: { buffer: buffers.output } }
          ]
        });
        
        const workgroups = Math.ceil(N / wgSize);
        const iterations = 100;
        
        for (let i = 0; i < 20; i++) {
          const enc = device.createCommandEncoder();
          const pass = enc.beginComputePass();
          pass.setPipeline(pipeline);
          pass.setBindGroup(0, bindGroup);
          pass.dispatchWorkgroups(workgroups);
          pass.end();
          device.queue.submit([enc.finish()]);
        }
        await device.queue.onSubmittedWorkDone();
        
        const start = performance.now();
        for (let i = 0; i < iterations; i++) {
          const enc = device.createCommandEncoder();
          const pass = enc.beginComputePass();
          pass.setPipeline(pipeline);
          pass.setBindGroup(0, bindGroup);
          pass.dispatchWorkgroups(workgroups);
          pass.end();
          device.queue.submit([enc.finish()]);
        }
        await device.queue.onSubmittedWorkDone();
        const time = (performance.now() - start) / iterations;
        
        for (const buf of Object.values(buffers)) buf.destroy();
        
        const bytes = K * 4 + q.packed.byteLength + q.scales.byteLength + N * 4;
        const bw = bytes / (time / 1000) / 1e9;
        
        return { time, bw };
      }
      
      const tests = [
        { name: 'V23 (baseline)', fn: createV23, wg: 64 },
        { name: 'V24 (extractBits)', fn: createV24, wg: 64 },
        { name: 'V25 (inner 4x)', fn: createV25, wg: 64 },
        { name: 'V27 (vec4 extract)', fn: createV27, wg: 64 },
        { name: 'V28 (fma)', fn: createV28, wg: 64 },
        { name: 'V29 (wg=48)', fn: createV29, wg: 48 },
      ];
      
      let best = null;
      
      for (const test of tests) {
        try {
          const r = await bench(test.name, test.fn, test.wg);
          const isBest = !best || r.time < best.time;
          log(`${test.name}: ${r.time.toFixed(3)}ms | ${r.bw.toFixed(2)} GB/s`, isBest ? 'pass' : '');
          if (isBest) {
            best = { ...r, name: test.name };
          }
        } catch (e) {
          log(`${test.name}: ERROR - ${e.message}`, 'fail');
        }
      }
      
      log('\n--- Summary ---', 'header');
      log(`Best: ${best.name} @ ${best.time.toFixed(3)}ms (${best.bw.toFixed(2)} GB/s)`);
      log(`Ceiling: 1.80ms (12.5 GB/s)`);
      log(`Gap: ${(best.time - 1.80).toFixed(3)}ms (${((best.time / 1.80 - 1) * 100).toFixed(1)}% overhead)`);
      log(`Efficiency: ${(12.5 / best.bw * 100).toFixed(1)}% of ceiling`);
    }
    
    benchmark().catch(e => {
      log(`ERROR: ${e.message}`, 'fail');
      console.error(e);
    });
  </script>
</body>
</html>
