<!DOCTYPE html>
<html>
<head>
  <title>INT4 Final Optimization V2</title>
  <style>
    body { font-family: monospace; padding: 20px; background: #1a1a2e; color: #eee; }
    pre { background: #16213e; padding: 15px; border-radius: 8px; }
    .pass { color: #4ade80; }
    .fail { color: #f87171; }
    .header { color: #c084fc; font-weight: bold; }
  </style>
</head>
<body>
  <h1>INT4 Final Optimization - V2</h1>
  <pre id="output"></pre>
  <script type="module">
    const log = (msg, cls = '') => {
      const span = cls ? `<span class="${cls}">${msg}</span>` : msg;
      document.getElementById('output').innerHTML += span + '\n';
    };

    function quantizeTransposed(K, N, groupSize) {
      const numGroups = Math.ceil(K / groupSize);
      const packedK = Math.ceil(K / 8);
      const packed = new Uint32Array(packedK * N);
      const scales = new Float32Array(numGroups * N);
      for (let i = 0; i < packed.length; i++) packed[i] = Math.random() * 0xFFFFFFFF >>> 0;
      for (let i = 0; i < scales.length; i++) scales[i] = Math.random() * 0.1;
      return { packed, scales, packedK, numGroups };
    }

    // V12 baseline (current best)
    function createV12(K, N, groupSize) {
      const numGroups = Math.ceil(K / groupSize);
      const packedK = Math.ceil(K / 8);
      const packedPerGroup = groupSize / 8;
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;

const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = ${packedPerGroup}u;

@compute @workgroup_size(256)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  
  var sum = 0.0;
  
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let scale = scales[g * N + col];
    
    for (var p = 0u; p < PACKED_PER_GROUP; p += 2u) {
      let packed_idx = g * PACKED_PER_GROUP + p;
      let k_base = packed_idx * 8u;
      
      let p0 = b_packed[packed_idx * N + col];
      let p1 = b_packed[(packed_idx + 1u) * N + col];
      
      let a0 = a[k_base / 4u];
      let a1 = a[k_base / 4u + 1u];
      let a2 = a[k_base / 4u + 2u];
      let a3 = a[k_base / 4u + 3u];
      
      sum += dot(a0, vec4<f32>(f32((p0>>0u)&0xFu)-8.0, f32((p0>>4u)&0xFu)-8.0, f32((p0>>8u)&0xFu)-8.0, f32((p0>>12u)&0xFu)-8.0) * scale);
      sum += dot(a1, vec4<f32>(f32((p0>>16u)&0xFu)-8.0, f32((p0>>20u)&0xFu)-8.0, f32((p0>>24u)&0xFu)-8.0, f32((p0>>28u)&0xFu)-8.0) * scale);
      sum += dot(a2, vec4<f32>(f32((p1>>0u)&0xFu)-8.0, f32((p1>>4u)&0xFu)-8.0, f32((p1>>8u)&0xFu)-8.0, f32((p1>>12u)&0xFu)-8.0) * scale);
      sum += dot(a3, vec4<f32>(f32((p1>>16u)&0xFu)-8.0, f32((p1>>20u)&0xFu)-8.0, f32((p1>>24u)&0xFu)-8.0, f32((p1>>28u)&0xFu)-8.0) * scale);
    }
  }
  output[col] = sum;
}`;
    }

    // V13: 8x unroll - process 64 weights per iteration
    function createV13(K, N, groupSize) {
      const numGroups = Math.ceil(K / groupSize);
      const packedK = Math.ceil(K / 8);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;

const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_K = ${packedK}u;
const GROUP_SIZE = ${groupSize}u;

@compute @workgroup_size(256)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  
  var sum = 0.0;
  
  for (var packed_idx = 0u; packed_idx < PACKED_K; packed_idx += 8u) {
    let k_base = packed_idx * 8u;
    let group_idx = k_base / GROUP_SIZE;
    let scale = scales[group_idx * N + col];
    
    let p0 = b_packed[packed_idx * N + col];
    let p1 = b_packed[(packed_idx + 1u) * N + col];
    let p2 = b_packed[(packed_idx + 2u) * N + col];
    let p3 = b_packed[(packed_idx + 3u) * N + col];
    let p4 = b_packed[(packed_idx + 4u) * N + col];
    let p5 = b_packed[(packed_idx + 5u) * N + col];
    let p6 = b_packed[(packed_idx + 6u) * N + col];
    let p7 = b_packed[(packed_idx + 7u) * N + col];
    
    let a0 = a[k_base/4u]; let a1 = a[k_base/4u+1u]; let a2 = a[k_base/4u+2u]; let a3 = a[k_base/4u+3u];
    let a4 = a[k_base/4u+4u]; let a5 = a[k_base/4u+5u]; let a6 = a[k_base/4u+6u]; let a7 = a[k_base/4u+7u];
    let a8 = a[k_base/4u+8u]; let a9 = a[k_base/4u+9u]; let a10 = a[k_base/4u+10u]; let a11 = a[k_base/4u+11u];
    let a12 = a[k_base/4u+12u]; let a13 = a[k_base/4u+13u]; let a14 = a[k_base/4u+14u]; let a15 = a[k_base/4u+15u];
    
    sum += dot(a0, vec4<f32>(f32((p0>>0u)&0xFu)-8.0, f32((p0>>4u)&0xFu)-8.0, f32((p0>>8u)&0xFu)-8.0, f32((p0>>12u)&0xFu)-8.0) * scale);
    sum += dot(a1, vec4<f32>(f32((p0>>16u)&0xFu)-8.0, f32((p0>>20u)&0xFu)-8.0, f32((p0>>24u)&0xFu)-8.0, f32((p0>>28u)&0xFu)-8.0) * scale);
    sum += dot(a2, vec4<f32>(f32((p1>>0u)&0xFu)-8.0, f32((p1>>4u)&0xFu)-8.0, f32((p1>>8u)&0xFu)-8.0, f32((p1>>12u)&0xFu)-8.0) * scale);
    sum += dot(a3, vec4<f32>(f32((p1>>16u)&0xFu)-8.0, f32((p1>>20u)&0xFu)-8.0, f32((p1>>24u)&0xFu)-8.0, f32((p1>>28u)&0xFu)-8.0) * scale);
    sum += dot(a4, vec4<f32>(f32((p2>>0u)&0xFu)-8.0, f32((p2>>4u)&0xFu)-8.0, f32((p2>>8u)&0xFu)-8.0, f32((p2>>12u)&0xFu)-8.0) * scale);
    sum += dot(a5, vec4<f32>(f32((p2>>16u)&0xFu)-8.0, f32((p2>>20u)&0xFu)-8.0, f32((p2>>24u)&0xFu)-8.0, f32((p2>>28u)&0xFu)-8.0) * scale);
    sum += dot(a6, vec4<f32>(f32((p3>>0u)&0xFu)-8.0, f32((p3>>4u)&0xFu)-8.0, f32((p3>>8u)&0xFu)-8.0, f32((p3>>12u)&0xFu)-8.0) * scale);
    sum += dot(a7, vec4<f32>(f32((p3>>16u)&0xFu)-8.0, f32((p3>>20u)&0xFu)-8.0, f32((p3>>24u)&0xFu)-8.0, f32((p3>>28u)&0xFu)-8.0) * scale);
    sum += dot(a8, vec4<f32>(f32((p4>>0u)&0xFu)-8.0, f32((p4>>4u)&0xFu)-8.0, f32((p4>>8u)&0xFu)-8.0, f32((p4>>12u)&0xFu)-8.0) * scale);
    sum += dot(a9, vec4<f32>(f32((p4>>16u)&0xFu)-8.0, f32((p4>>20u)&0xFu)-8.0, f32((p4>>24u)&0xFu)-8.0, f32((p4>>28u)&0xFu)-8.0) * scale);
    sum += dot(a10, vec4<f32>(f32((p5>>0u)&0xFu)-8.0, f32((p5>>4u)&0xFu)-8.0, f32((p5>>8u)&0xFu)-8.0, f32((p5>>12u)&0xFu)-8.0) * scale);
    sum += dot(a11, vec4<f32>(f32((p5>>16u)&0xFu)-8.0, f32((p5>>20u)&0xFu)-8.0, f32((p5>>24u)&0xFu)-8.0, f32((p5>>28u)&0xFu)-8.0) * scale);
    sum += dot(a12, vec4<f32>(f32((p6>>0u)&0xFu)-8.0, f32((p6>>4u)&0xFu)-8.0, f32((p6>>8u)&0xFu)-8.0, f32((p6>>12u)&0xFu)-8.0) * scale);
    sum += dot(a13, vec4<f32>(f32((p6>>16u)&0xFu)-8.0, f32((p6>>20u)&0xFu)-8.0, f32((p6>>24u)&0xFu)-8.0, f32((p6>>28u)&0xFu)-8.0) * scale);
    sum += dot(a14, vec4<f32>(f32((p7>>0u)&0xFu)-8.0, f32((p7>>4u)&0xFu)-8.0, f32((p7>>8u)&0xFu)-8.0, f32((p7>>12u)&0xFu)-8.0) * scale);
    sum += dot(a15, vec4<f32>(f32((p7>>16u)&0xFu)-8.0, f32((p7>>20u)&0xFu)-8.0, f32((p7>>24u)&0xFu)-8.0, f32((p7>>28u)&0xFu)-8.0) * scale);
  }
  output[col] = sum;
}`;
    }

    // V14: 8x unroll + group-aware scale caching
    function createV14(K, N, groupSize) {
      const numGroups = Math.ceil(K / groupSize);
      const packedK = Math.ceil(K / 8);
      const packedPerGroup = groupSize / 8;
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;

const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = ${packedPerGroup}u;

@compute @workgroup_size(256)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  
  var sum = 0.0;
  
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let scale = scales[g * N + col];
    let packed_base = g * PACKED_PER_GROUP;
    
    // Process 8 packed u32s (64 weights) per group iteration  
    // Group size 128 = 16 packed, so we do 2 iterations
    for (var i = 0u; i < PACKED_PER_GROUP; i += 8u) {
      let packed_idx = packed_base + i;
      let k_base = packed_idx * 8u;
      
      let p0 = b_packed[packed_idx * N + col];
      let p1 = b_packed[(packed_idx + 1u) * N + col];
      let p2 = b_packed[(packed_idx + 2u) * N + col];
      let p3 = b_packed[(packed_idx + 3u) * N + col];
      let p4 = b_packed[(packed_idx + 4u) * N + col];
      let p5 = b_packed[(packed_idx + 5u) * N + col];
      let p6 = b_packed[(packed_idx + 6u) * N + col];
      let p7 = b_packed[(packed_idx + 7u) * N + col];
      
      let a0 = a[k_base/4u]; let a1 = a[k_base/4u+1u]; let a2 = a[k_base/4u+2u]; let a3 = a[k_base/4u+3u];
      let a4 = a[k_base/4u+4u]; let a5 = a[k_base/4u+5u]; let a6 = a[k_base/4u+6u]; let a7 = a[k_base/4u+7u];
      let a8 = a[k_base/4u+8u]; let a9 = a[k_base/4u+9u]; let a10 = a[k_base/4u+10u]; let a11 = a[k_base/4u+11u];
      let a12 = a[k_base/4u+12u]; let a13 = a[k_base/4u+13u]; let a14 = a[k_base/4u+14u]; let a15 = a[k_base/4u+15u];
      
      sum += dot(a0, vec4<f32>(f32((p0>>0u)&0xFu)-8.0, f32((p0>>4u)&0xFu)-8.0, f32((p0>>8u)&0xFu)-8.0, f32((p0>>12u)&0xFu)-8.0) * scale);
      sum += dot(a1, vec4<f32>(f32((p0>>16u)&0xFu)-8.0, f32((p0>>20u)&0xFu)-8.0, f32((p0>>24u)&0xFu)-8.0, f32((p0>>28u)&0xFu)-8.0) * scale);
      sum += dot(a2, vec4<f32>(f32((p1>>0u)&0xFu)-8.0, f32((p1>>4u)&0xFu)-8.0, f32((p1>>8u)&0xFu)-8.0, f32((p1>>12u)&0xFu)-8.0) * scale);
      sum += dot(a3, vec4<f32>(f32((p1>>16u)&0xFu)-8.0, f32((p1>>20u)&0xFu)-8.0, f32((p1>>24u)&0xFu)-8.0, f32((p1>>28u)&0xFu)-8.0) * scale);
      sum += dot(a4, vec4<f32>(f32((p2>>0u)&0xFu)-8.0, f32((p2>>4u)&0xFu)-8.0, f32((p2>>8u)&0xFu)-8.0, f32((p2>>12u)&0xFu)-8.0) * scale);
      sum += dot(a5, vec4<f32>(f32((p2>>16u)&0xFu)-8.0, f32((p2>>20u)&0xFu)-8.0, f32((p2>>24u)&0xFu)-8.0, f32((p2>>28u)&0xFu)-8.0) * scale);
      sum += dot(a6, vec4<f32>(f32((p3>>0u)&0xFu)-8.0, f32((p3>>4u)&0xFu)-8.0, f32((p3>>8u)&0xFu)-8.0, f32((p3>>12u)&0xFu)-8.0) * scale);
      sum += dot(a7, vec4<f32>(f32((p3>>16u)&0xFu)-8.0, f32((p3>>20u)&0xFu)-8.0, f32((p3>>24u)&0xFu)-8.0, f32((p3>>28u)&0xFu)-8.0) * scale);
      sum += dot(a8, vec4<f32>(f32((p4>>0u)&0xFu)-8.0, f32((p4>>4u)&0xFu)-8.0, f32((p4>>8u)&0xFu)-8.0, f32((p4>>12u)&0xFu)-8.0) * scale);
      sum += dot(a9, vec4<f32>(f32((p4>>16u)&0xFu)-8.0, f32((p4>>20u)&0xFu)-8.0, f32((p4>>24u)&0xFu)-8.0, f32((p4>>28u)&0xFu)-8.0) * scale);
      sum += dot(a10, vec4<f32>(f32((p5>>0u)&0xFu)-8.0, f32((p5>>4u)&0xFu)-8.0, f32((p5>>8u)&0xFu)-8.0, f32((p5>>12u)&0xFu)-8.0) * scale);
      sum += dot(a11, vec4<f32>(f32((p5>>16u)&0xFu)-8.0, f32((p5>>20u)&0xFu)-8.0, f32((p5>>24u)&0xFu)-8.0, f32((p5>>28u)&0xFu)-8.0) * scale);
      sum += dot(a12, vec4<f32>(f32((p6>>0u)&0xFu)-8.0, f32((p6>>4u)&0xFu)-8.0, f32((p6>>8u)&0xFu)-8.0, f32((p6>>12u)&0xFu)-8.0) * scale);
      sum += dot(a13, vec4<f32>(f32((p6>>16u)&0xFu)-8.0, f32((p6>>20u)&0xFu)-8.0, f32((p6>>24u)&0xFu)-8.0, f32((p6>>28u)&0xFu)-8.0) * scale);
      sum += dot(a14, vec4<f32>(f32((p7>>0u)&0xFu)-8.0, f32((p7>>4u)&0xFu)-8.0, f32((p7>>8u)&0xFu)-8.0, f32((p7>>12u)&0xFu)-8.0) * scale);
      sum += dot(a15, vec4<f32>(f32((p7>>16u)&0xFu)-8.0, f32((p7>>20u)&0xFu)-8.0, f32((p7>>24u)&0xFu)-8.0, f32((p7>>28u)&0xFu)-8.0) * scale);
    }
  }
  output[col] = sum;
}`;
    }

    // V15: Even larger group size (256)
    function createV15(K, N, groupSize256) {
      const numGroups = Math.ceil(K / 256);
      const packedK = Math.ceil(K / 8);
      const packedPerGroup = 256 / 8;  // 32
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;

const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = ${packedPerGroup}u;

@compute @workgroup_size(256)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  
  var sum = 0.0;
  
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let scale = scales[g * N + col];
    let packed_base = g * PACKED_PER_GROUP;
    
    for (var i = 0u; i < PACKED_PER_GROUP; i += 8u) {
      let packed_idx = packed_base + i;
      let k_base = packed_idx * 8u;
      
      let p0 = b_packed[packed_idx * N + col];
      let p1 = b_packed[(packed_idx + 1u) * N + col];
      let p2 = b_packed[(packed_idx + 2u) * N + col];
      let p3 = b_packed[(packed_idx + 3u) * N + col];
      let p4 = b_packed[(packed_idx + 4u) * N + col];
      let p5 = b_packed[(packed_idx + 5u) * N + col];
      let p6 = b_packed[(packed_idx + 6u) * N + col];
      let p7 = b_packed[(packed_idx + 7u) * N + col];
      
      let a0 = a[k_base/4u]; let a1 = a[k_base/4u+1u]; let a2 = a[k_base/4u+2u]; let a3 = a[k_base/4u+3u];
      let a4 = a[k_base/4u+4u]; let a5 = a[k_base/4u+5u]; let a6 = a[k_base/4u+6u]; let a7 = a[k_base/4u+7u];
      let a8 = a[k_base/4u+8u]; let a9 = a[k_base/4u+9u]; let a10 = a[k_base/4u+10u]; let a11 = a[k_base/4u+11u];
      let a12 = a[k_base/4u+12u]; let a13 = a[k_base/4u+13u]; let a14 = a[k_base/4u+14u]; let a15 = a[k_base/4u+15u];
      
      sum += dot(a0, vec4<f32>(f32((p0>>0u)&0xFu)-8.0, f32((p0>>4u)&0xFu)-8.0, f32((p0>>8u)&0xFu)-8.0, f32((p0>>12u)&0xFu)-8.0) * scale);
      sum += dot(a1, vec4<f32>(f32((p0>>16u)&0xFu)-8.0, f32((p0>>20u)&0xFu)-8.0, f32((p0>>24u)&0xFu)-8.0, f32((p0>>28u)&0xFu)-8.0) * scale);
      sum += dot(a2, vec4<f32>(f32((p1>>0u)&0xFu)-8.0, f32((p1>>4u)&0xFu)-8.0, f32((p1>>8u)&0xFu)-8.0, f32((p1>>12u)&0xFu)-8.0) * scale);
      sum += dot(a3, vec4<f32>(f32((p1>>16u)&0xFu)-8.0, f32((p1>>20u)&0xFu)-8.0, f32((p1>>24u)&0xFu)-8.0, f32((p1>>28u)&0xFu)-8.0) * scale);
      sum += dot(a4, vec4<f32>(f32((p2>>0u)&0xFu)-8.0, f32((p2>>4u)&0xFu)-8.0, f32((p2>>8u)&0xFu)-8.0, f32((p2>>12u)&0xFu)-8.0) * scale);
      sum += dot(a5, vec4<f32>(f32((p2>>16u)&0xFu)-8.0, f32((p2>>20u)&0xFu)-8.0, f32((p2>>24u)&0xFu)-8.0, f32((p2>>28u)&0xFu)-8.0) * scale);
      sum += dot(a6, vec4<f32>(f32((p3>>0u)&0xFu)-8.0, f32((p3>>4u)&0xFu)-8.0, f32((p3>>8u)&0xFu)-8.0, f32((p3>>12u)&0xFu)-8.0) * scale);
      sum += dot(a7, vec4<f32>(f32((p3>>16u)&0xFu)-8.0, f32((p3>>20u)&0xFu)-8.0, f32((p3>>24u)&0xFu)-8.0, f32((p3>>28u)&0xFu)-8.0) * scale);
      sum += dot(a8, vec4<f32>(f32((p4>>0u)&0xFu)-8.0, f32((p4>>4u)&0xFu)-8.0, f32((p4>>8u)&0xFu)-8.0, f32((p4>>12u)&0xFu)-8.0) * scale);
      sum += dot(a9, vec4<f32>(f32((p4>>16u)&0xFu)-8.0, f32((p4>>20u)&0xFu)-8.0, f32((p4>>24u)&0xFu)-8.0, f32((p4>>28u)&0xFu)-8.0) * scale);
      sum += dot(a10, vec4<f32>(f32((p5>>0u)&0xFu)-8.0, f32((p5>>4u)&0xFu)-8.0, f32((p5>>8u)&0xFu)-8.0, f32((p5>>12u)&0xFu)-8.0) * scale);
      sum += dot(a11, vec4<f32>(f32((p5>>16u)&0xFu)-8.0, f32((p5>>20u)&0xFu)-8.0, f32((p5>>24u)&0xFu)-8.0, f32((p5>>28u)&0xFu)-8.0) * scale);
      sum += dot(a12, vec4<f32>(f32((p6>>0u)&0xFu)-8.0, f32((p6>>4u)&0xFu)-8.0, f32((p6>>8u)&0xFu)-8.0, f32((p6>>12u)&0xFu)-8.0) * scale);
      sum += dot(a13, vec4<f32>(f32((p6>>16u)&0xFu)-8.0, f32((p6>>20u)&0xFu)-8.0, f32((p6>>24u)&0xFu)-8.0, f32((p6>>28u)&0xFu)-8.0) * scale);
      sum += dot(a14, vec4<f32>(f32((p7>>0u)&0xFu)-8.0, f32((p7>>4u)&0xFu)-8.0, f32((p7>>8u)&0xFu)-8.0, f32((p7>>12u)&0xFu)-8.0) * scale);
      sum += dot(a15, vec4<f32>(f32((p7>>16u)&0xFu)-8.0, f32((p7>>20u)&0xFu)-8.0, f32((p7>>24u)&0xFu)-8.0, f32((p7>>28u)&0xFu)-8.0) * scale);
    }
  }
  output[col] = sum;
}`;
    }

    async function benchmark() {
      log('=== INT4 Final Optimization V2 ===\n', 'header');
      
      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice({
        requiredLimits: {
          maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,
          maxBufferSize: adapter.limits.maxBufferSize
        }
      });
      
      const configs = [
        { K: 4096, N: 4096, name: 'QKV [4096→4096]' },
        { K: 4096, N: 11008, name: 'Gate/Up [4096→11008]' },
        { K: 11008, N: 4096, name: 'Down [11008→4096]' },
      ];
      
      async function benchShader(shaderFn, K, N, groupSize) {
        const q = quantizeTransposed(K, N, groupSize);
        
        const buffers = {
          a: device.createBuffer({ size: K * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
          packed: device.createBuffer({ size: q.packed.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
          scales: device.createBuffer({ size: q.scales.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
          output: device.createBuffer({ size: N * 4, usage: GPUBufferUsage.STORAGE })
        };
        
        device.queue.writeBuffer(buffers.a, 0, new Float32Array(K).fill(0.1));
        device.queue.writeBuffer(buffers.packed, 0, q.packed);
        device.queue.writeBuffer(buffers.scales, 0, q.scales);
        
        const module = device.createShaderModule({ code: shaderFn(K, N, groupSize) });
        const pipeline = device.createComputePipeline({
          layout: 'auto',
          compute: { module, entryPoint: 'main' }
        });
        
        const bindGroup = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [
            { binding: 0, resource: { buffer: buffers.a } },
            { binding: 1, resource: { buffer: buffers.packed } },
            { binding: 2, resource: { buffer: buffers.scales } },
            { binding: 3, resource: { buffer: buffers.output } }
          ]
        });
        
        const workgroups = Math.ceil(N / 256);
        const iterations = 50;
        
        for (let i = 0; i < 10; i++) {
          const enc = device.createCommandEncoder();
          const pass = enc.beginComputePass();
          pass.setPipeline(pipeline);
          pass.setBindGroup(0, bindGroup);
          pass.dispatchWorkgroups(workgroups);
          pass.end();
          device.queue.submit([enc.finish()]);
        }
        await device.queue.onSubmittedWorkDone();
        
        const start = performance.now();
        for (let i = 0; i < iterations; i++) {
          const enc = device.createCommandEncoder();
          const pass = enc.beginComputePass();
          pass.setPipeline(pipeline);
          pass.setBindGroup(0, bindGroup);
          pass.dispatchWorkgroups(workgroups);
          pass.end();
          device.queue.submit([enc.finish()]);
        }
        await device.queue.onSubmittedWorkDone();
        const time = (performance.now() - start) / iterations;
        
        for (const buf of Object.values(buffers)) buf.destroy();
        
        const bytes = K * 4 + q.packed.byteLength + q.scales.byteLength + N * 4;
        const bw = bytes / (time / 1000) / 1e9;
        
        return { time, bw };
      }
      
      const results = {};
      
      for (const cfg of configs) {
        log(`\n--- ${cfg.name} ---`, 'header');
        results[cfg.name] = { best: null, bestName: '' };
        
        const tests = [
          { name: 'V12 (baseline)', fn: createV12, gs: 128 },
          { name: 'V13 (8x unroll)', fn: createV13, gs: 128 },
          { name: 'V14 (8x + group)', fn: createV14, gs: 128 },
          { name: 'V15 (gs=256)', fn: createV15, gs: 256 },
        ];
        
        for (const test of tests) {
          const r = await benchShader(test.fn, cfg.K, cfg.N, test.gs);
          const isBest = !results[cfg.name].best || r.time < results[cfg.name].best.time;
          log(`${test.name}: ${r.time.toFixed(2)}ms | ${r.bw.toFixed(2)} GB/s`, isBest ? 'pass' : '');
          if (isBest) {
            results[cfg.name].best = r;
            results[cfg.name].bestName = test.name;
          }
        }
        
        log(`Best: ${results[cfg.name].bestName} @ ${results[cfg.name].best.bw.toFixed(2)} GB/s`, 'pass');
      }
      
      // Final 7B projection
      log('\n\n=== 7B MODEL PROJECTION ===\n', 'header');
      
      const qkvTime = results['QKV [4096→4096]'].best.time * 4;
      const gateUpTime = results['Gate/Up [4096→11008]'].best.time * 2;
      const downTime = results['Down [11008→4096]'].best.time;
      const matmulPerLayer = qkvTime + gateUpTime + downTime;
      
      log(`Per layer:`);
      log(`  QKV (x4):    ${qkvTime.toFixed(2)}ms`);
      log(`  Gate/Up (x2): ${gateUpTime.toFixed(2)}ms`);
      log(`  Down:        ${downTime.toFixed(2)}ms`);
      log(`  Total:       ${matmulPerLayer.toFixed(2)}ms`);
      
      const matmulTotal = matmulPerLayer * 32;
      const otherOps = (0.09 * 2 + 0.31 + 0.46) * 32;  // Optimized RMSNorm + RoPE + attention
      const total = matmulTotal + otherOps;
      
      log(`\n32 layers:`);
      log(`  MatMul:      ${matmulTotal.toFixed(0)}ms`);
      log(`  Other ops:   ${otherOps.toFixed(0)}ms`);
      log(`  Total:       ${total.toFixed(0)}ms`);
      log(`  Tokens/sec:  ${(1000 / total).toFixed(2)}`, (1000 / total) > 2.5 ? 'pass' : 'warn');
    }
    
    benchmark().catch(e => {
      log(`ERROR: ${e.message}`, 'fail');
      console.error(e);
    });
  </script>
</body>
</html>
