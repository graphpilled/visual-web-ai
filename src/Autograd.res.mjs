// Generated by ReScript, PLEASE EDIT WITH CARE

import * as Shape from "./Shape.res.mjs";
import * as Stdlib_Array from "@rescript/runtime/lib/es6/Stdlib_Array.js";
import * as Primitive_int from "@rescript/runtime/lib/es6/Primitive_int.js";
import * as Stdlib_Option from "@rescript/runtime/lib/es6/Stdlib_Option.js";

function storageBufferRO(binding, name) {
  return `@group(0) @binding(` + binding.toString() + `) var<storage, read> ` + name + `: array<f32>;`;
}

function storageBufferRW(binding, name) {
  return `@group(0) @binding(` + binding.toString() + `) var<storage, read_write> ` + name + `: array<f32>;`;
}

let mainSignature = `@compute @workgroup_size(` + (256).toString() + `)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let idx = gid.x;`;

let mainEnd = "}";

function computeDispatch(totalElements, kernelName, pipelineIndex) {
  let workgroupCount = ((totalElements + 256 | 0) - 1 | 0) / 256 | 0;
  return {
    workgroupSize: [
      256,
      1,
      1
    ],
    workgroupCount: [
      workgroupCount,
      1,
      1
    ],
    kernelName: kernelName,
    pipelineIndex: pipelineIndex
  };
}

function genGradReduceKernel(gradShape, targetShape) {
  let gradSize = Shape.numElements(gradShape);
  let targetSize = Shape.numElements(targetShape);
  let gradRank = gradShape.length;
  let targetRank = targetShape.length;
  let maxRank = Primitive_int.max(gradRank, targetRank);
  let paddedGrad = Stdlib_Array.make(maxRank - gradRank | 0, 1).concat(gradShape);
  let paddedTarget = Stdlib_Array.make(maxRank - targetRank | 0, 1).concat(targetShape);
  paddedTarget.map((dim, i) => [
    dim,
    i
  ]).filter((elem, _idx) => {
    if (elem[0] === 1) {
      return Stdlib_Option.getOr(paddedGrad[elem[1]], 1) > 1;
    } else {
      return false;
    }
  }).map(param => param[1]);
  let gradStrides = Stdlib_Array.fromInitializer(maxRank, i => {
    let stride = 1;
    for (let j = i + 1 | 0; j < maxRank; ++j) {
      stride = stride * Stdlib_Option.getOr(paddedGrad[j], 1) | 0;
    }
    return stride;
  });
  let targetStrides = Stdlib_Array.fromInitializer(maxRank, i => {
    let stride = 1;
    for (let j = i + 1 | 0; j < maxRank; ++j) {
      stride = stride * Stdlib_Option.getOr(paddedTarget[j], 1) | 0;
    }
    return stride;
  });
  let gradShapeStr = paddedGrad.map(d => d.toString()).join(", ");
  let targetShapeStr = paddedTarget.map(d => d.toString()).join(", ");
  let gradStridesStr = gradStrides.map(d => d.toString()).join(", ");
  let targetStridesStr = targetStrides.map(d => d.toString()).join(", ");
  let wgsl = targetSize === gradSize ? storageBufferRO(0, "grad_in") + `
` + storageBufferRW(1, "grad_out") + `
` + mainSignature + `
  if (idx >= ` + targetSize.toString() + `u) { return; }
  grad_out[idx] = grad_in[idx];
` + mainEnd : storageBufferRO(0, "grad_in") + `
` + storageBufferRW(1, "grad_out") + `
const RANK = ` + maxRank.toString() + `u;
const GRAD_SIZE = ` + gradSize.toString() + `u;
const TARGET_SIZE = ` + targetSize.toString() + `u;
const GRAD_SHAPE = array<u32, ` + maxRank.toString() + `>(` + gradShapeStr + `);
const TARGET_SHAPE = array<u32, ` + maxRank.toString() + `>(` + targetShapeStr + `);
const GRAD_STRIDES = array<u32, ` + maxRank.toString() + `>(` + gradStridesStr + `);
const TARGET_STRIDES = array<u32, ` + maxRank.toString() + `>(` + targetStridesStr + `);
` + mainSignature + `
  if (idx >= TARGET_SIZE) { return; }
  
  // Convert target idx to coordinates
  var target_coords: array<u32, ` + maxRank.toString() + `>;
  var remaining = idx;
  for (var d = 0u; d < RANK; d = d + 1u) {
    target_coords[d] = remaining / TARGET_STRIDES[d];
    remaining = remaining % TARGET_STRIDES[d];
  }
  
  // Sum over all grad elements that map to this target element
  var sum = 0.0;
  for (var g = 0u; g < GRAD_SIZE; g = g + 1u) {
    // Convert grad idx to coordinates
    var grad_coords: array<u32, ` + maxRank.toString() + `>;
    var rem = g;
    for (var d = 0u; d < RANK; d = d + 1u) {
      grad_coords[d] = rem / GRAD_STRIDES[d];
      rem = rem % GRAD_STRIDES[d];
    }
    
    // Check if this grad element maps to our target element
    var matches = true;
    for (var d = 0u; d < RANK; d = d + 1u) {
      if (TARGET_SHAPE[d] > 1u && grad_coords[d] != target_coords[d]) {
        matches = false;
        break;
      }
    }
    
    if (matches) {
      sum = sum + grad_in[g];
    }
  }
  
  grad_out[idx] = sum;
` + mainEnd;
  return {
    name: "grad_reduce_" + gradSize.toString() + "_to_" + targetSize.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (gradSize << 2),
        usage: "ReadOnly",
        name: "grad_in"
      },
      {
        binding: 1,
        size: (targetSize << 2),
        usage: "ReadWrite",
        name: "grad_out"
      }
    ]
  };
}

function genNegBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRW(1, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_x[idx] = -grad_out[idx];
` + mainEnd;
  return {
    name: "neg_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genAbsBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "x") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_x[idx] = grad_out[idx] * sign(x[idx]);
` + mainEnd;
  return {
    name: "abs_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "x"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genSqrtBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "out") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let out_val = out[idx];
  grad_x[idx] = select(0.0, grad_out[idx] * 0.5 / out_val, out_val > 0.0);
` + mainEnd;
  return {
    name: "sqrt_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "out"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genExpBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "out") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_x[idx] = grad_out[idx] * out[idx];
` + mainEnd;
  return {
    name: "exp_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "out"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genLogBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "x") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_x[idx] = grad_out[idx] / x[idx];
` + mainEnd;
  return {
    name: "log_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "x"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genSinBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "x") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_x[idx] = grad_out[idx] * cos(x[idx]);
` + mainEnd;
  return {
    name: "sin_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "x"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genCosBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "x") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_x[idx] = -grad_out[idx] * sin(x[idx]);
` + mainEnd;
  return {
    name: "cos_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "x"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genTanhBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "out") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let t = out[idx];
  grad_x[idx] = grad_out[idx] * (1.0 - t * t);
` + mainEnd;
  return {
    name: "tanh_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "out"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genSigmoidBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "out") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let s = out[idx];
  grad_x[idx] = grad_out[idx] * s * (1.0 - s);
` + mainEnd;
  return {
    name: "sigmoid_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "out"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genReLUBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "x") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_x[idx] = select(0.0, grad_out[idx], x[idx] > 0.0);
` + mainEnd;
  return {
    name: "relu_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "x"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genLeakyReLUBackwardKernel(size, alpha) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "x") + `
` + storageBufferRW(2, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let g = grad_out[idx];
  grad_x[idx] = select(` + alpha.toString() + ` * g, g, x[idx] > 0.0);
` + mainEnd;
  return {
    name: "leaky_relu_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "x"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genGeLUBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "x") + `
` + storageBufferRW(2, "grad_x") + `
const SQRT_2 = 1.4142135623730951;
const SQRT_2_PI = 0.7978845608028654;
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let x_val = x[idx];
  let cdf = 0.5 * (1.0 + tanh(SQRT_2 / 2.0 * (x_val + 0.044715 * x_val * x_val * x_val)));
  let pdf = SQRT_2_PI * exp(-0.5 * x_val * x_val);
  grad_x[idx] = grad_out[idx] * (cdf + x_val * pdf);
` + mainEnd;
  return {
    name: "gelu_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "x"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genAddBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRW(1, "grad_a") + `
` + storageBufferRW(2, "grad_b") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let g = grad_out[idx];
  grad_a[idx] = g;
  grad_b[idx] = g;
` + mainEnd;
  return {
    name: "add_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_a"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genSubBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRW(1, "grad_a") + `
` + storageBufferRW(2, "grad_b") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let g = grad_out[idx];
  grad_a[idx] = g;
  grad_b[idx] = -g;
` + mainEnd;
  return {
    name: "sub_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_a"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genMulBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "a") + `
` + storageBufferRO(2, "b") + `
` + storageBufferRW(3, "grad_a") + `
` + storageBufferRW(4, "grad_b") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let g = grad_out[idx];
  grad_a[idx] = g * b[idx];
  grad_b[idx] = g * a[idx];
` + mainEnd;
  return {
    name: "mul_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "a"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadOnly",
        name: "b"
      },
      {
        binding: 3,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_a"
      },
      {
        binding: 4,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genDivBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "a") + `
` + storageBufferRO(2, "b") + `
` + storageBufferRW(3, "grad_a") + `
` + storageBufferRW(4, "grad_b") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let g = grad_out[idx];
  let b_val = b[idx];
  grad_a[idx] = g / b_val;
  grad_b[idx] = -g * a[idx] / (b_val * b_val);
` + mainEnd;
  return {
    name: "div_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "a"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadOnly",
        name: "b"
      },
      {
        binding: 3,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_a"
      },
      {
        binding: 4,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genPowBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "a") + `
` + storageBufferRO(2, "b") + `
` + storageBufferRO(3, "out") + `
` + storageBufferRW(4, "grad_a") + `
` + storageBufferRW(5, "grad_b") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let g = grad_out[idx];
  let a_val = a[idx];
  let b_val = b[idx];
  let out_val = out[idx];
  // dL/da = g * b * a^(b-1) = g * b * out / a
  grad_a[idx] = select(0.0, g * b_val * out_val / a_val, a_val != 0.0);
  // dL/db = g * a^b * ln(a) = g * out * ln(a)
  grad_b[idx] = select(0.0, g * out_val * log(a_val), a_val > 0.0);
` + mainEnd;
  return {
    name: "pow_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "a"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadOnly",
        name: "b"
      },
      {
        binding: 3,
        size: (size << 2),
        usage: "ReadOnly",
        name: "out"
      },
      {
        binding: 4,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_a"
      },
      {
        binding: 5,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genMaximumBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "a") + `
` + storageBufferRO(2, "b") + `
` + storageBufferRW(3, "grad_a") + `
` + storageBufferRW(4, "grad_b") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let g = grad_out[idx];
  let a_val = a[idx];
  let b_val = b[idx];
  if (a_val > b_val) {
    grad_a[idx] = g;
    grad_b[idx] = 0.0;
  } else if (b_val > a_val) {
    grad_a[idx] = 0.0;
    grad_b[idx] = g;
  } else {
    // Equal: split gradient
    grad_a[idx] = g * 0.5;
    grad_b[idx] = g * 0.5;
  }
` + mainEnd;
  return {
    name: "maximum_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "a"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadOnly",
        name: "b"
      },
      {
        binding: 3,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_a"
      },
      {
        binding: 4,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genMinimumBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "a") + `
` + storageBufferRO(2, "b") + `
` + storageBufferRW(3, "grad_a") + `
` + storageBufferRW(4, "grad_b") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let g = grad_out[idx];
  let a_val = a[idx];
  let b_val = b[idx];
  if (a_val < b_val) {
    grad_a[idx] = g;
    grad_b[idx] = 0.0;
  } else if (b_val < a_val) {
    grad_a[idx] = 0.0;
    grad_b[idx] = g;
  } else {
    grad_a[idx] = g * 0.5;
    grad_b[idx] = g * 0.5;
  }
` + mainEnd;
  return {
    name: "minimum_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "a"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadOnly",
        name: "b"
      },
      {
        binding: 3,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_a"
      },
      {
        binding: 4,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genMatMulBackwardAKernel(m, k, n) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "b") + `
` + storageBufferRW(2, "grad_a") + `
const M = ` + m.toString() + `u;
const K = ` + k.toString() + `u;
const N = ` + n.toString() + `u;
@compute @workgroup_size(16, 16)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let row = gid.y;
  let col = gid.x;
  if (row >= M || col >= K) { return; }
  
  var sum = 0.0;
  for (var i = 0u; i < N; i = i + 1u) {
    // grad_out[row, i] * b[col, i] (B transposed: b[k, n] -> b^T[n, k])
    sum = sum + grad_out[row * N + i] * b[col * N + i];
  }
  grad_a[row * K + col] = sum;
}`;
  return {
    name: "matmul_backward_a_" + m.toString() + "x" + k.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: ((m * n | 0) << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: ((k * n | 0) << 2),
        usage: "ReadOnly",
        name: "b"
      },
      {
        binding: 2,
        size: ((m * k | 0) << 2),
        usage: "ReadWrite",
        name: "grad_a"
      }
    ]
  };
}

function genMatMulBackwardBKernel(m, k, n) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "a") + `
` + storageBufferRW(2, "grad_b") + `
const M = ` + m.toString() + `u;
const K = ` + k.toString() + `u;
const N = ` + n.toString() + `u;
@compute @workgroup_size(16, 16)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let row = gid.y;
  let col = gid.x;
  if (row >= K || col >= N) { return; }
  
  var sum = 0.0;
  for (var i = 0u; i < M; i = i + 1u) {
    // a[i, row] (A transposed: a[m, k] -> a^T[k, m]) * grad_out[i, col]
    sum = sum + a[i * K + row] * grad_out[i * N + col];
  }
  grad_b[row * N + col] = sum;
}`;
  return {
    name: "matmul_backward_b_" + k.toString() + "x" + n.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: ((m * n | 0) << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: ((m * k | 0) << 2),
        usage: "ReadOnly",
        name: "a"
      },
      {
        binding: 2,
        size: ((k * n | 0) << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genBatchedMatMulBackwardAKernel(batch, m, k, n) {
  let totalOutput = (batch * m | 0) * k | 0;
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "b") + `
` + storageBufferRW(2, "grad_a") + `
const BATCH = ` + batch.toString() + `u;
const M = ` + m.toString() + `u;
const K = ` + k.toString() + `u;
const N = ` + n.toString() + `u;
` + mainSignature + `
  if (idx >= ` + totalOutput.toString() + `u) { return; }
  
  let batch_idx = idx / (M * K);
  let matrix_idx = idx % (M * K);
  let row = matrix_idx / K;
  let col = matrix_idx % K;
  
  var sum = 0.0;
  let grad_base = batch_idx * M * N;
  let b_base = batch_idx * K * N;
  
  for (var i = 0u; i < N; i = i + 1u) {
    sum = sum + grad_out[grad_base + row * N + i] * b[b_base + col * N + i];
  }
  grad_a[idx] = sum;
` + mainEnd;
  return {
    name: "batched_matmul_backward_a_" + batch.toString() + "_" + m.toString() + "x" + k.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (((batch * m | 0) * n | 0) << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (((batch * k | 0) * n | 0) << 2),
        usage: "ReadOnly",
        name: "b"
      },
      {
        binding: 2,
        size: (((batch * m | 0) * k | 0) << 2),
        usage: "ReadWrite",
        name: "grad_a"
      }
    ]
  };
}

function genBatchedMatMulBackwardBKernel(batch, m, k, n) {
  let totalOutput = (batch * k | 0) * n | 0;
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "a") + `
` + storageBufferRW(2, "grad_b") + `
const BATCH = ` + batch.toString() + `u;
const M = ` + m.toString() + `u;
const K = ` + k.toString() + `u;
const N = ` + n.toString() + `u;
` + mainSignature + `
  if (idx >= ` + totalOutput.toString() + `u) { return; }
  
  let batch_idx = idx / (K * N);
  let matrix_idx = idx % (K * N);
  let row = matrix_idx / N;
  let col = matrix_idx % N;
  
  var sum = 0.0;
  let grad_base = batch_idx * M * N;
  let a_base = batch_idx * M * K;
  
  for (var i = 0u; i < M; i = i + 1u) {
    sum = sum + a[a_base + i * K + row] * grad_out[grad_base + i * N + col];
  }
  grad_b[idx] = sum;
` + mainEnd;
  return {
    name: "batched_matmul_backward_b_" + batch.toString() + "_" + k.toString() + "x" + n.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (((batch * m | 0) * n | 0) << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (((batch * m | 0) * k | 0) << 2),
        usage: "ReadOnly",
        name: "a"
      },
      {
        binding: 2,
        size: (((batch * k | 0) * n | 0) << 2),
        usage: "ReadWrite",
        name: "grad_b"
      }
    ]
  };
}

function genSumBackwardKernel(inputShape, outputShape, axes) {
  let inputSize = Shape.numElements(inputShape);
  let outputSize = Shape.numElements(outputShape);
  let rank = inputShape.length;
  let inputStrides = Stdlib_Array.fromInitializer(rank, i => {
    let stride = 1;
    for (let j = i + 1 | 0; j < rank; ++j) {
      stride = stride * Stdlib_Option.getOr(inputShape[j], 1) | 0;
    }
    return stride;
  });
  let normAxes = axes.map(a => {
    if (a < 0) {
      return rank + a | 0;
    } else {
      return a;
    }
  });
  let strides = [];
  let stride = 1;
  for (let i = rank - 1 | 0; i >= 0; --i) {
    if (!normAxes.includes(i)) {
      strides = [stride].concat(strides);
    }
    stride = stride * Stdlib_Option.getOr(inputShape[i], 1) | 0;
  }
  let inputShapeStr = inputShape.map(d => d.toString()).join(", ");
  let inputStridesStr = inputStrides.map(d => d.toString()).join(", ");
  let axesStr = normAxes.map(d => d.toString()).join(", ");
  let numAxes = normAxes.length;
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRW(1, "grad_x") + `
const RANK = ` + rank.toString() + `u;
const INPUT_SIZE = ` + inputSize.toString() + `u;
const OUTPUT_SIZE = ` + outputSize.toString() + `u;
const NUM_AXES = ` + numAxes.toString() + `u;
const INPUT_SHAPE = array<u32, ` + rank.toString() + `>(` + inputShapeStr + `);
const INPUT_STRIDES = array<u32, ` + rank.toString() + `>(` + inputStridesStr + `);
const AXES = array<u32, ` + numAxes.toString() + `>(` + axesStr + `);

fn isReduceAxis(axis: u32) -> bool {
  for (var i = 0u; i < NUM_AXES; i = i + 1u) {
    if (AXES[i] == axis) { return true; }
  }
  return false;
}

` + mainSignature + `
  if (idx >= INPUT_SIZE) { return; }
  
  // Convert flat idx to coordinates
  var coords: array<u32, ` + rank.toString() + `>;
  var remaining = idx;
  for (var d = 0u; d < RANK; d = d + 1u) {
    coords[d] = remaining / INPUT_STRIDES[d];
    remaining = remaining % INPUT_STRIDES[d];
  }
  
  // Compute output index (skip reduced dimensions)
  var out_idx = 0u;
  var out_stride = 1u;
  for (var d = i32(RANK) - 1; d >= 0; d = d - 1) {
    if (!isReduceAxis(u32(d))) {
      out_idx = out_idx + coords[d] * out_stride;
      out_stride = out_stride * INPUT_SHAPE[d];
    }
  }
  
  grad_x[idx] = grad_out[out_idx];
` + mainEnd;
  return {
    name: "sum_backward_" + inputSize.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (outputSize << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (inputSize << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genMeanBackwardKernel(inputShape, outputShape, axes) {
  let inputSize = Shape.numElements(inputShape);
  let outputSize = Shape.numElements(outputShape);
  let rank = inputShape.length;
  let normAxes = axes.map(a => {
    if (a < 0) {
      return rank + a | 0;
    } else {
      return a;
    }
  });
  let reduceCount = Stdlib_Array.reduce(normAxes, 1, (acc, axis) => acc * Stdlib_Option.getOr(inputShape[axis], 1) | 0);
  let inputStrides = Stdlib_Array.fromInitializer(rank, i => {
    let stride = 1;
    for (let j = i + 1 | 0; j < rank; ++j) {
      stride = stride * Stdlib_Option.getOr(inputShape[j], 1) | 0;
    }
    return stride;
  });
  let inputShapeStr = inputShape.map(d => d.toString()).join(", ");
  let inputStridesStr = inputStrides.map(d => d.toString()).join(", ");
  let axesStr = normAxes.map(d => d.toString()).join(", ");
  let numAxes = normAxes.length;
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRW(1, "grad_x") + `
const RANK = ` + rank.toString() + `u;
const INPUT_SIZE = ` + inputSize.toString() + `u;
const REDUCE_COUNT = ` + reduceCount.toString() + `;
const NUM_AXES = ` + numAxes.toString() + `u;
const INPUT_SHAPE = array<u32, ` + rank.toString() + `>(` + inputShapeStr + `);
const INPUT_STRIDES = array<u32, ` + rank.toString() + `>(` + inputStridesStr + `);
const AXES = array<u32, ` + numAxes.toString() + `>(` + axesStr + `);

fn isReduceAxis(axis: u32) -> bool {
  for (var i = 0u; i < NUM_AXES; i = i + 1u) {
    if (AXES[i] == axis) { return true; }
  }
  return false;
}

` + mainSignature + `
  if (idx >= INPUT_SIZE) { return; }
  
  var coords: array<u32, ` + rank.toString() + `>;
  var remaining = idx;
  for (var d = 0u; d < RANK; d = d + 1u) {
    coords[d] = remaining / INPUT_STRIDES[d];
    remaining = remaining % INPUT_STRIDES[d];
  }
  
  var out_idx = 0u;
  var out_stride = 1u;
  for (var d = i32(RANK) - 1; d >= 0; d = d - 1) {
    if (!isReduceAxis(u32(d))) {
      out_idx = out_idx + coords[d] * out_stride;
      out_stride = out_stride * INPUT_SHAPE[d];
    }
  }
  
  grad_x[idx] = grad_out[out_idx] / REDUCE_COUNT;
` + mainEnd;
  return {
    name: "mean_backward_" + inputSize.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (outputSize << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (inputSize << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genSoftmaxBackwardKernel(outerSize, axisSize) {
  let totalSize = outerSize * axisSize | 0;
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "softmax_out") + `
` + storageBufferRW(2, "grad_x") + `
const OUTER_SIZE = ` + outerSize.toString() + `u;
const AXIS_SIZE = ` + axisSize.toString() + `u;
` + mainSignature + `
  let outer_idx = idx;
  if (outer_idx >= OUTER_SIZE) { return; }
  
  let base = outer_idx * AXIS_SIZE;
  
  // Compute dot product: sum_j(grad_out[j] * softmax[j])
  var dot = 0.0;
  for (var j = 0u; j < AXIS_SIZE; j = j + 1u) {
    dot = dot + grad_out[base + j] * softmax_out[base + j];
  }
  
  // grad_x[i] = softmax[i] * (grad_out[i] - dot)
  for (var i = 0u; i < AXIS_SIZE; i = i + 1u) {
    let s = softmax_out[base + i];
    grad_x[base + i] = s * (grad_out[base + i] - dot);
  }
` + mainEnd;
  return {
    name: "softmax_backward_" + outerSize.toString() + "x" + axisSize.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (totalSize << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (totalSize << 2),
        usage: "ReadOnly",
        name: "softmax_out"
      },
      {
        binding: 2,
        size: (totalSize << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genLayerNormBackwardKernel(outerSize, normSize, epsilon) {
  let totalSize = outerSize * normSize | 0;
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRO(1, "x") + `
` + storageBufferRO(2, "gamma") + `
` + storageBufferRW(3, "grad_x") + `
` + storageBufferRW(4, "grad_gamma") + `
` + storageBufferRW(5, "grad_beta") + `
const OUTER = ` + outerSize.toString() + `u;
const NORM = ` + normSize.toString() + `u;
const EPSILON = ` + epsilon.toString() + `;
` + mainSignature + `
  let outer_idx = idx;
  if (outer_idx >= OUTER) { return; }
  
  let base = outer_idx * NORM;
  
  // Recompute mean and variance
  var mean = 0.0;
  for (var i = 0u; i < NORM; i = i + 1u) {
    mean = mean + x[base + i];
  }
  mean = mean / f32(NORM);
  
  var variance = 0.0;
  for (var i = 0u; i < NORM; i = i + 1u) {
    let diff = x[base + i] - mean;
    variance = variance + diff * diff;
  }
  variance = variance / f32(NORM);
  let inv_std = 1.0 / sqrt(variance + EPSILON);
  
  // Compute intermediate sums for gradient
  var sum_grad_out = 0.0;
  var sum_grad_out_x_centered = 0.0;
  for (var i = 0u; i < NORM; i = i + 1u) {
    let g = grad_out[base + i] * gamma[i];
    sum_grad_out = sum_grad_out + g;
    sum_grad_out_x_centered = sum_grad_out_x_centered + g * (x[base + i] - mean);
  }
  
  // Compute grad_x
  let norm_factor = 1.0 / f32(NORM);
  for (var i = 0u; i < NORM; i = i + 1u) {
    let x_centered = x[base + i] - mean;
    let x_norm = x_centered * inv_std;
    let g = grad_out[base + i] * gamma[i];
    grad_x[base + i] = inv_std * (g - norm_factor * sum_grad_out - norm_factor * x_norm * sum_grad_out_x_centered * inv_std);
  }
  
  // Accumulate grad_gamma and grad_beta (atomic would be better but this works for single outer)
  if (outer_idx == 0u) {
    for (var i = 0u; i < NORM; i = i + 1u) {
      var gg = 0.0;
      var gb = 0.0;
      for (var o = 0u; o < OUTER; o = o + 1u) {
        let b = o * NORM;
        var m = 0.0;
        for (var j = 0u; j < NORM; j = j + 1u) { m = m + x[b + j]; }
        m = m / f32(NORM);
        var v = 0.0;
        for (var j = 0u; j < NORM; j = j + 1u) { let d = x[b + j] - m; v = v + d * d; }
        v = v / f32(NORM);
        let istd = 1.0 / sqrt(v + EPSILON);
        let x_norm = (x[b + i] - m) * istd;
        gg = gg + grad_out[b + i] * x_norm;
        gb = gb + grad_out[b + i];
      }
      grad_gamma[i] = gg;
      grad_beta[i] = gb;
    }
  }
` + mainEnd;
  return {
    name: "layernorm_backward_" + outerSize.toString() + "x" + normSize.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (totalSize << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (totalSize << 2),
        usage: "ReadOnly",
        name: "x"
      },
      {
        binding: 2,
        size: (normSize << 2),
        usage: "ReadOnly",
        name: "gamma"
      },
      {
        binding: 3,
        size: (totalSize << 2),
        usage: "ReadWrite",
        name: "grad_x"
      },
      {
        binding: 4,
        size: (normSize << 2),
        usage: "ReadWrite",
        name: "grad_gamma"
      },
      {
        binding: 5,
        size: (normSize << 2),
        usage: "ReadWrite",
        name: "grad_beta"
      }
    ]
  };
}

function genCopyBackwardKernel(size) {
  let wgsl = storageBufferRO(0, "grad_out") + `
` + storageBufferRW(1, "grad_x") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_x[idx] = grad_out[idx];
` + mainEnd;
  return {
    name: "copy_backward_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_out"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_x"
      }
    ]
  };
}

function genGradAccumulateKernel(size) {
  let wgsl = storageBufferRW(0, "grad_acc") + `
` + storageBufferRO(1, "grad_new") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad_acc[idx] = grad_acc[idx] + grad_new[idx];
` + mainEnd;
  return {
    name: "grad_accumulate_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad_acc"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad_new"
      }
    ]
  };
}

function genGradZeroKernel(size) {
  let wgsl = storageBufferRW(0, "grad") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  grad[idx] = 0.0;
` + mainEnd;
  return {
    name: "grad_zero_" + size.toString(),
    wgsl: wgsl,
    bindings: [{
        binding: 0,
        size: (size << 2),
        usage: "ReadWrite",
        name: "grad"
      }]
  };
}

function genSGDKernel(size, lr) {
  let wgsl = storageBufferRW(0, "param") + `
` + storageBufferRO(1, "grad") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  param[idx] = param[idx] - ` + lr.toString() + ` * grad[idx];
` + mainEnd;
  return {
    name: "sgd_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadWrite",
        name: "param"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad"
      }
    ]
  };
}

function genSGDMomentumKernel(size, lr, momentum) {
  let wgsl = storageBufferRW(0, "param") + `
` + storageBufferRO(1, "grad") + `
` + storageBufferRW(2, "velocity") + `
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  let v = ` + momentum.toString() + ` * velocity[idx] + grad[idx];
  velocity[idx] = v;
  param[idx] = param[idx] - ` + lr.toString() + ` * v;
` + mainEnd;
  return {
    name: "sgd_momentum_" + size.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadWrite",
        name: "param"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "velocity"
      }
    ]
  };
}

function genAdamKernel(size, lr, beta1, beta2, epsilon, t) {
  let beta1_t = Math.pow(beta1, t);
  let beta2_t = Math.pow(beta2, t);
  let lr_t = lr * Math.sqrt(1.0 - beta2_t) / (1.0 - beta1_t);
  let wgsl = storageBufferRW(0, "param") + `
` + storageBufferRO(1, "grad") + `
` + storageBufferRW(2, "m") + `
` + storageBufferRW(3, "v") + `
const LR_T = ` + lr_t.toString() + `;
const BETA1 = ` + beta1.toString() + `;
const BETA2 = ` + beta2.toString() + `;
const EPSILON = ` + epsilon.toString() + `;
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  
  let g = grad[idx];
  
  // Update biased first moment estimate
  let m_new = BETA1 * m[idx] + (1.0 - BETA1) * g;
  m[idx] = m_new;
  
  // Update biased second raw moment estimate  
  let v_new = BETA2 * v[idx] + (1.0 - BETA2) * g * g;
  v[idx] = v_new;
  
  // Update parameters (bias correction already in LR_T)
  param[idx] = param[idx] - LR_T * m_new / (sqrt(v_new) + EPSILON);
` + mainEnd;
  return {
    name: "adam_" + size.toString() + "_t" + t.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadWrite",
        name: "param"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "m"
      },
      {
        binding: 3,
        size: (size << 2),
        usage: "ReadWrite",
        name: "v"
      }
    ]
  };
}

function genAdamWKernel(size, lr, beta1, beta2, epsilon, weightDecay, t) {
  let beta1_t = Math.pow(beta1, t);
  let beta2_t = Math.pow(beta2, t);
  let lr_t = lr * Math.sqrt(1.0 - beta2_t) / (1.0 - beta1_t);
  let wgsl = storageBufferRW(0, "param") + `
` + storageBufferRO(1, "grad") + `
` + storageBufferRW(2, "m") + `
` + storageBufferRW(3, "v") + `
const LR = ` + lr.toString() + `;
const LR_T = ` + lr_t.toString() + `;
const BETA1 = ` + beta1.toString() + `;
const BETA2 = ` + beta2.toString() + `;
const EPSILON = ` + epsilon.toString() + `;
const WEIGHT_DECAY = ` + weightDecay.toString() + `;
` + mainSignature + `
  if (idx >= ` + size.toString() + `u) { return; }
  
  let g = grad[idx];
  let p = param[idx];
  
  // Update moments
  let m_new = BETA1 * m[idx] + (1.0 - BETA1) * g;
  m[idx] = m_new;
  let v_new = BETA2 * v[idx] + (1.0 - BETA2) * g * g;
  v[idx] = v_new;
  
  // Update with decoupled weight decay
  param[idx] = p - LR_T * m_new / (sqrt(v_new) + EPSILON) - LR * WEIGHT_DECAY * p;
` + mainEnd;
  return {
    name: "adamw_" + size.toString() + "_t" + t.toString(),
    wgsl: wgsl,
    bindings: [
      {
        binding: 0,
        size: (size << 2),
        usage: "ReadWrite",
        name: "param"
      },
      {
        binding: 1,
        size: (size << 2),
        usage: "ReadOnly",
        name: "grad"
      },
      {
        binding: 2,
        size: (size << 2),
        usage: "ReadWrite",
        name: "m"
      },
      {
        binding: 3,
        size: (size << 2),
        usage: "ReadWrite",
        name: "v"
      }
    ]
  };
}

let workgroupSize = 256;

export {
  workgroupSize,
  storageBufferRO,
  storageBufferRW,
  mainSignature,
  mainEnd,
  computeDispatch,
  genGradReduceKernel,
  genNegBackwardKernel,
  genAbsBackwardKernel,
  genSqrtBackwardKernel,
  genExpBackwardKernel,
  genLogBackwardKernel,
  genSinBackwardKernel,
  genCosBackwardKernel,
  genTanhBackwardKernel,
  genSigmoidBackwardKernel,
  genReLUBackwardKernel,
  genLeakyReLUBackwardKernel,
  genGeLUBackwardKernel,
  genAddBackwardKernel,
  genSubBackwardKernel,
  genMulBackwardKernel,
  genDivBackwardKernel,
  genPowBackwardKernel,
  genMaximumBackwardKernel,
  genMinimumBackwardKernel,
  genMatMulBackwardAKernel,
  genMatMulBackwardBKernel,
  genBatchedMatMulBackwardAKernel,
  genBatchedMatMulBackwardBKernel,
  genSumBackwardKernel,
  genMeanBackwardKernel,
  genSoftmaxBackwardKernel,
  genLayerNormBackwardKernel,
  genCopyBackwardKernel,
  genGradAccumulateKernel,
  genGradZeroKernel,
  genSGDKernel,
  genSGDMomentumKernel,
  genAdamKernel,
  genAdamWKernel,
}
/* mainSignature Not a pure module */
