<!DOCTYPE html>
<html>
<head>
  <title>INT4 MatMul Debug</title>
  <style>
    body { font-family: monospace; padding: 20px; background: #1a1a2e; color: #eee; }
    pre { background: #16213e; padding: 15px; border-radius: 8px; }
    .pass { color: #4ade80; }
    .fail { color: #f87171; }
  </style>
</head>
<body>
  <h1>INT4 MatMul Debug Test</h1>
  <pre id="output"></pre>
  <script type="module">
    const log = (msg, cls = '') => {
      const span = cls ? `<span class="${cls}">${msg}</span>` : msg;
      document.getElementById('output').innerHTML += span + '\n';
    };

    // V29 kernel from int4-variance-test.html
    function createV29(K, N, groupSize) {
      const numGroups = Math.ceil(K / groupSize);
      return `
@group(0) @binding(0) var<storage, read> a: array<vec4<f32>>;
@group(0) @binding(1) var<storage, read> b_packed: array<u32>;
@group(0) @binding(2) var<storage, read> scales: array<f32>;
@group(0) @binding(3) var<storage, read_write> output: array<f32>;
const N = ${N}u;
const NUM_GROUPS = ${numGroups}u;
const PACKED_PER_GROUP = 16u;
@compute @workgroup_size(48)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
  let col = gid.x;
  if (col >= N) { return; }
  var sum = 0.0;
  for (var g = 0u; g < NUM_GROUPS; g++) {
    let s = scales[g * N + col];
    let base = g * PACKED_PER_GROUP;
    var acc = 0.0;
    let p0 = b_packed[base * N + col];
    let p1 = b_packed[(base + 1u) * N + col];
    let p2 = b_packed[(base + 2u) * N + col];
    let p3 = b_packed[(base + 3u) * N + col];
    let p4 = b_packed[(base + 4u) * N + col];
    let p5 = b_packed[(base + 5u) * N + col];
    let p6 = b_packed[(base + 6u) * N + col];
    let p7 = b_packed[(base + 7u) * N + col];
    let k0 = base * 8u;
    let a0 = a[k0/4u]; let a1 = a[k0/4u+1u]; let a2 = a[k0/4u+2u]; let a3 = a[k0/4u+3u];
    let a4 = a[k0/4u+4u]; let a5 = a[k0/4u+5u]; let a6 = a[k0/4u+6u]; let a7 = a[k0/4u+7u];
    let a8 = a[k0/4u+8u]; let a9 = a[k0/4u+9u]; let a10 = a[k0/4u+10u]; let a11 = a[k0/4u+11u];
    let a12 = a[k0/4u+12u]; let a13 = a[k0/4u+13u]; let a14 = a[k0/4u+14u]; let a15 = a[k0/4u+15u];
    acc += dot(a0, vec4<f32>(f32((p0>>0u)&0xFu)-8.0, f32((p0>>4u)&0xFu)-8.0, f32((p0>>8u)&0xFu)-8.0, f32((p0>>12u)&0xFu)-8.0));
    acc += dot(a1, vec4<f32>(f32((p0>>16u)&0xFu)-8.0, f32((p0>>20u)&0xFu)-8.0, f32((p0>>24u)&0xFu)-8.0, f32((p0>>28u)&0xFu)-8.0));
    acc += dot(a2, vec4<f32>(f32((p1>>0u)&0xFu)-8.0, f32((p1>>4u)&0xFu)-8.0, f32((p1>>8u)&0xFu)-8.0, f32((p1>>12u)&0xFu)-8.0));
    acc += dot(a3, vec4<f32>(f32((p1>>16u)&0xFu)-8.0, f32((p1>>20u)&0xFu)-8.0, f32((p1>>24u)&0xFu)-8.0, f32((p1>>28u)&0xFu)-8.0));
    acc += dot(a4, vec4<f32>(f32((p2>>0u)&0xFu)-8.0, f32((p2>>4u)&0xFu)-8.0, f32((p2>>8u)&0xFu)-8.0, f32((p2>>12u)&0xFu)-8.0));
    acc += dot(a5, vec4<f32>(f32((p2>>16u)&0xFu)-8.0, f32((p2>>20u)&0xFu)-8.0, f32((p2>>24u)&0xFu)-8.0, f32((p2>>28u)&0xFu)-8.0));
    acc += dot(a6, vec4<f32>(f32((p3>>0u)&0xFu)-8.0, f32((p3>>4u)&0xFu)-8.0, f32((p3>>8u)&0xFu)-8.0, f32((p3>>12u)&0xFu)-8.0));
    acc += dot(a7, vec4<f32>(f32((p3>>16u)&0xFu)-8.0, f32((p3>>20u)&0xFu)-8.0, f32((p3>>24u)&0xFu)-8.0, f32((p3>>28u)&0xFu)-8.0));
    acc += dot(a8, vec4<f32>(f32((p4>>0u)&0xFu)-8.0, f32((p4>>4u)&0xFu)-8.0, f32((p4>>8u)&0xFu)-8.0, f32((p4>>12u)&0xFu)-8.0));
    acc += dot(a9, vec4<f32>(f32((p4>>16u)&0xFu)-8.0, f32((p4>>20u)&0xFu)-8.0, f32((p4>>24u)&0xFu)-8.0, f32((p4>>28u)&0xFu)-8.0));
    acc += dot(a10, vec4<f32>(f32((p5>>0u)&0xFu)-8.0, f32((p5>>4u)&0xFu)-8.0, f32((p5>>8u)&0xFu)-8.0, f32((p5>>12u)&0xFu)-8.0));
    acc += dot(a11, vec4<f32>(f32((p5>>16u)&0xFu)-8.0, f32((p5>>20u)&0xFu)-8.0, f32((p5>>24u)&0xFu)-8.0, f32((p5>>28u)&0xFu)-8.0));
    acc += dot(a12, vec4<f32>(f32((p6>>0u)&0xFu)-8.0, f32((p6>>4u)&0xFu)-8.0, f32((p6>>8u)&0xFu)-8.0, f32((p6>>12u)&0xFu)-8.0));
    acc += dot(a13, vec4<f32>(f32((p6>>16u)&0xFu)-8.0, f32((p6>>20u)&0xFu)-8.0, f32((p6>>24u)&0xFu)-8.0, f32((p6>>28u)&0xFu)-8.0));
    acc += dot(a14, vec4<f32>(f32((p7>>0u)&0xFu)-8.0, f32((p7>>4u)&0xFu)-8.0, f32((p7>>8u)&0xFu)-8.0, f32((p7>>12u)&0xFu)-8.0));
    acc += dot(a15, vec4<f32>(f32((p7>>16u)&0xFu)-8.0, f32((p7>>20u)&0xFu)-8.0, f32((p7>>24u)&0xFu)-8.0, f32((p7>>28u)&0xFu)-8.0));
    let q0 = b_packed[(base + 8u) * N + col];
    let q1 = b_packed[(base + 9u) * N + col];
    let q2 = b_packed[(base + 10u) * N + col];
    let q3 = b_packed[(base + 11u) * N + col];
    let q4 = b_packed[(base + 12u) * N + col];
    let q5 = b_packed[(base + 13u) * N + col];
    let q6 = b_packed[(base + 14u) * N + col];
    let q7 = b_packed[(base + 15u) * N + col];
    let k1 = (base + 8u) * 8u;
    let b0 = a[k1/4u]; let b1 = a[k1/4u+1u]; let b2 = a[k1/4u+2u]; let b3 = a[k1/4u+3u];
    let b4 = a[k1/4u+4u]; let b5 = a[k1/4u+5u]; let b6 = a[k1/4u+6u]; let b7 = a[k1/4u+7u];
    let b8 = a[k1/4u+8u]; let b9 = a[k1/4u+9u]; let b10 = a[k1/4u+10u]; let b11 = a[k1/4u+11u];
    let b12 = a[k1/4u+12u]; let b13 = a[k1/4u+13u]; let b14 = a[k1/4u+14u]; let b15 = a[k1/4u+15u];
    acc += dot(b0, vec4<f32>(f32((q0>>0u)&0xFu)-8.0, f32((q0>>4u)&0xFu)-8.0, f32((q0>>8u)&0xFu)-8.0, f32((q0>>12u)&0xFu)-8.0));
    acc += dot(b1, vec4<f32>(f32((q0>>16u)&0xFu)-8.0, f32((q0>>20u)&0xFu)-8.0, f32((q0>>24u)&0xFu)-8.0, f32((q0>>28u)&0xFu)-8.0));
    acc += dot(b2, vec4<f32>(f32((q1>>0u)&0xFu)-8.0, f32((q1>>4u)&0xFu)-8.0, f32((q1>>8u)&0xFu)-8.0, f32((q1>>12u)&0xFu)-8.0));
    acc += dot(b3, vec4<f32>(f32((q1>>16u)&0xFu)-8.0, f32((q1>>20u)&0xFu)-8.0, f32((q1>>24u)&0xFu)-8.0, f32((q1>>28u)&0xFu)-8.0));
    acc += dot(b4, vec4<f32>(f32((q2>>0u)&0xFu)-8.0, f32((q2>>4u)&0xFu)-8.0, f32((q2>>8u)&0xFu)-8.0, f32((q2>>12u)&0xFu)-8.0));
    acc += dot(b5, vec4<f32>(f32((q2>>16u)&0xFu)-8.0, f32((q2>>20u)&0xFu)-8.0, f32((q2>>24u)&0xFu)-8.0, f32((q2>>28u)&0xFu)-8.0));
    acc += dot(b6, vec4<f32>(f32((q3>>0u)&0xFu)-8.0, f32((q3>>4u)&0xFu)-8.0, f32((q3>>8u)&0xFu)-8.0, f32((q3>>12u)&0xFu)-8.0));
    acc += dot(b7, vec4<f32>(f32((q3>>16u)&0xFu)-8.0, f32((q3>>20u)&0xFu)-8.0, f32((q3>>24u)&0xFu)-8.0, f32((q3>>28u)&0xFu)-8.0));
    acc += dot(b8, vec4<f32>(f32((q4>>0u)&0xFu)-8.0, f32((q4>>4u)&0xFu)-8.0, f32((q4>>8u)&0xFu)-8.0, f32((q4>>12u)&0xFu)-8.0));
    acc += dot(b9, vec4<f32>(f32((q4>>16u)&0xFu)-8.0, f32((q4>>20u)&0xFu)-8.0, f32((q4>>24u)&0xFu)-8.0, f32((q4>>28u)&0xFu)-8.0));
    acc += dot(b10, vec4<f32>(f32((q5>>0u)&0xFu)-8.0, f32((q5>>4u)&0xFu)-8.0, f32((q5>>8u)&0xFu)-8.0, f32((q5>>12u)&0xFu)-8.0));
    acc += dot(b11, vec4<f32>(f32((q5>>16u)&0xFu)-8.0, f32((q5>>20u)&0xFu)-8.0, f32((q5>>24u)&0xFu)-8.0, f32((q5>>28u)&0xFu)-8.0));
    acc += dot(b12, vec4<f32>(f32((q6>>0u)&0xFu)-8.0, f32((q6>>4u)&0xFu)-8.0, f32((q6>>8u)&0xFu)-8.0, f32((q6>>12u)&0xFu)-8.0));
    acc += dot(b13, vec4<f32>(f32((q6>>16u)&0xFu)-8.0, f32((q6>>20u)&0xFu)-8.0, f32((q6>>24u)&0xFu)-8.0, f32((q6>>28u)&0xFu)-8.0));
    acc += dot(b14, vec4<f32>(f32((q7>>0u)&0xFu)-8.0, f32((q7>>4u)&0xFu)-8.0, f32((q7>>8u)&0xFu)-8.0, f32((q7>>12u)&0xFu)-8.0));
    acc += dot(b15, vec4<f32>(f32((q7>>16u)&0xFu)-8.0, f32((q7>>20u)&0xFu)-8.0, f32((q7>>24u)&0xFu)-8.0, f32((q7>>28u)&0xFu)-8.0));
    sum += acc * s;
  }
  output[col] = sum;
}`;
    }

    // CPU reference implementation
    function int4MatmulCPU(input, packed, scales, K, N, groupSize) {
      const numGroups = Math.ceil(K / groupSize);
      const packedPerGroup = groupSize / 8;
      const output = new Float32Array(N);
      
      for (let col = 0; col < N; col++) {
        let sum = 0;
        for (let g = 0; g < numGroups; g++) {
          const s = scales[g * N + col];
          let acc = 0;
          
          for (let p = 0; p < packedPerGroup; p++) {
            const packedVal = packed[(g * packedPerGroup + p) * N + col];
            
            for (let sub = 0; sub < 8; sub++) {
              const row = g * groupSize + p * 8 + sub;
              if (row < K) {
                const w = ((packedVal >> (sub * 4)) & 0xF) - 8;  // Signed int4
                acc += input[row] * w;
              }
            }
          }
          sum += acc * s;
        }
        output[col] = sum;
      }
      return output;
    }

    async function runTest() {
      log('=== INT4 MatMul Debug Test ===\n');
      
      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice();
      log(' WebGPU initialized');
      
      // Small test: K=128, N=64 (single group)
      const K = 128, N = 64, groupSize = 128;
      const numGroups = Math.ceil(K / groupSize);
      const packedPerGroup = groupSize / 8;
      
      log(`\nTest 1: K=${K}, N=${N}, groups=${numGroups}`);
      
      // Create known test data
      const input = new Float32Array(K);
      for (let i = 0; i < K; i++) input[i] = 0.1;  // All 0.1
      
      // Packed weights: all zeros (which decode to -8)
      const packed = new Uint32Array(numGroups * packedPerGroup * N);
      // All zeros means each 4-bit value is 0, decoded as 0-8 = -8
      
      // Scales: all 0.01
      const scales = new Float32Array(numGroups * N);
      for (let i = 0; i < scales.length; i++) scales[i] = 0.01;
      
      // CPU reference
      const cpuOutput = int4MatmulCPU(input, packed, scales, K, N, groupSize);
      log(`CPU output[0]: ${cpuOutput[0].toFixed(6)}`);
      log(`CPU output[N-1]: ${cpuOutput[N-1].toFixed(6)}`);
      // Expected: 128 * 0.1 * (-8) * 0.01 = -1.024
      log(`Expected: 128 * 0.1 * (-8) * 0.01 = ${128 * 0.1 * (-8) * 0.01}`);
      
      // GPU test
      const buffers = {
        a: device.createBuffer({ size: K * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
        packed: device.createBuffer({ size: packed.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
        scales: device.createBuffer({ size: scales.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST }),
        output: device.createBuffer({ size: N * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC })
      };
      
      device.queue.writeBuffer(buffers.a, 0, input);
      device.queue.writeBuffer(buffers.packed, 0, packed);
      device.queue.writeBuffer(buffers.scales, 0, scales);
      
      const module = device.createShaderModule({ code: createV29(K, N, groupSize) });
      const pipeline = device.createComputePipeline({ layout: 'auto', compute: { module, entryPoint: 'main' } });
      const bindGroup = device.createBindGroup({
        layout: pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: buffers.a } },
          { binding: 1, resource: { buffer: buffers.packed } },
          { binding: 2, resource: { buffer: buffers.scales } },
          { binding: 3, resource: { buffer: buffers.output } }
        ]
      });
      
      const enc = device.createCommandEncoder();
      const pass = enc.beginComputePass();
      pass.setPipeline(pipeline);
      pass.setBindGroup(0, bindGroup);
      pass.dispatchWorkgroups(Math.ceil(N / 48));
      pass.end();
      device.queue.submit([enc.finish()]);
      
      // Read result
      const readBuffer = device.createBuffer({ size: N * 4, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
      const enc2 = device.createCommandEncoder();
      enc2.copyBufferToBuffer(buffers.output, 0, readBuffer, 0, N * 4);
      device.queue.submit([enc2.finish()]);
      
      await readBuffer.mapAsync(GPUMapMode.READ);
      const gpuOutput = new Float32Array(readBuffer.getMappedRange().slice(0));
      readBuffer.unmap();
      
      log(`GPU output[0]: ${gpuOutput[0].toFixed(6)}`);
      log(`GPU output[N-1]: ${gpuOutput[N-1].toFixed(6)}`);
      
      // Compare
      let maxDiff = 0;
      for (let i = 0; i < N; i++) {
        maxDiff = Math.max(maxDiff, Math.abs(cpuOutput[i] - gpuOutput[i]));
      }
      
      if (maxDiff < 0.001) {
        log(`\n PASS - max diff: ${maxDiff.toExponential(2)}`, 'pass');
      } else {
        log(`\n FAIL - max diff: ${maxDiff.toExponential(2)}`, 'fail');
      }
      
      // Test 2: Non-trivial weights
      log('\n\nTest 2: Non-trivial weights');
      const packed2 = new Uint32Array(numGroups * packedPerGroup * N);
      // Set all int4 values to 8 (which decodes to 8-8=0)
      for (let i = 0; i < packed2.length; i++) packed2[i] = 0x88888888;
      
      const cpu2 = int4MatmulCPU(input, packed2, scales, K, N, groupSize);
      log(`CPU output (all weights=0): ${cpu2[0].toFixed(6)} (expected 0)`);
      
      device.queue.writeBuffer(buffers.packed, 0, packed2);
      
      const enc3 = device.createCommandEncoder();
      const pass3 = enc3.beginComputePass();
      pass3.setPipeline(pipeline);
      pass3.setBindGroup(0, bindGroup);
      pass3.dispatchWorkgroups(Math.ceil(N / 48));
      pass3.end();
      device.queue.submit([enc3.finish()]);
      
      const enc4 = device.createCommandEncoder();
      enc4.copyBufferToBuffer(buffers.output, 0, readBuffer, 0, N * 4);
      device.queue.submit([enc4.finish()]);
      
      await readBuffer.mapAsync(GPUMapMode.READ);
      const gpu2 = new Float32Array(readBuffer.getMappedRange().slice(0));
      readBuffer.unmap();
      
      log(`GPU output (all weights=0): ${gpu2[0].toFixed(6)}`);
      
      if (Math.abs(gpu2[0]) < 0.001) {
        log(' PASS', 'pass');
      } else {
        log(' FAIL', 'fail');
      }
      
      // Test 3: Positive weights
      log('\n\nTest 3: Positive weights (all +7)');
      const packed3 = new Uint32Array(numGroups * packedPerGroup * N);
      // Set all int4 values to 15 (which decodes to 15-8=7)
      for (let i = 0; i < packed3.length; i++) packed3[i] = 0xFFFFFFFF;
      
      const cpu3 = int4MatmulCPU(input, packed3, scales, K, N, groupSize);
      log(`CPU output: ${cpu3[0].toFixed(6)}`);
      log(`Expected: 128 * 0.1 * 7 * 0.01 = ${128 * 0.1 * 7 * 0.01}`);
      
      device.queue.writeBuffer(buffers.packed, 0, packed3);
      
      const enc5 = device.createCommandEncoder();
      const pass5 = enc5.beginComputePass();
      pass5.setPipeline(pipeline);
      pass5.setBindGroup(0, bindGroup);
      pass5.dispatchWorkgroups(Math.ceil(N / 48));
      pass5.end();
      device.queue.submit([enc5.finish()]);
      
      const enc6 = device.createCommandEncoder();
      enc6.copyBufferToBuffer(buffers.output, 0, readBuffer, 0, N * 4);
      device.queue.submit([enc6.finish()]);
      
      await readBuffer.mapAsync(GPUMapMode.READ);
      const gpu3 = new Float32Array(readBuffer.getMappedRange().slice(0));
      readBuffer.unmap();
      
      log(`GPU output: ${gpu3[0].toFixed(6)}`);
      
      maxDiff = Math.abs(cpu3[0] - gpu3[0]);
      if (maxDiff < 0.001) {
        log(' PASS', 'pass');
      } else {
        log(` FAIL - diff: ${maxDiff}`, 'fail');
      }
      
      log('\n=== Tests Complete ===');
    }

    runTest().catch(e => {
      log(`ERROR: ${e.message}`, 'fail');
      console.error(e);
    });
  </script>
</body>
</html>
